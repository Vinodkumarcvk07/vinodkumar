{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Reshape, Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Let's load the cifar dataset and examine what it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 4\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(x_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('Max of x:', np.max(x_train), '\\nMax of y:', np.max(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50000 images in train, each image of size (32, 32, 3).\n",
    "\n",
    "There are 10 classes of images and each image has a max of 255 pixel value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a CNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), input_shape=((32, 32, 3)), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((2,2), padding='same'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((2,2), padding='same'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "model.add(Conv2D(16, (5,5), padding='same', activation='relu'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "model.add(Conv2D(3, (5,5), padding='same', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice that we standardize the image as `x_train/255.0` during input feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrs = ReduceLROnPlateau(verbose=1, epsilon=0.01)\n",
    "model.fit(x_train/255.0, x_train/255.0, epochs=10, callbacks=[lrs], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "n = np.random.randint(0, high=50000)\n",
    "x_pred = model.predict(np.array([x_train[n]/255.0]), verbose=0)\n",
    "x_pred.shape\n",
    "# 121 stands for (1 row, 2 columns, 1st plot in the grid)\n",
    "plt.subplot(121)\n",
    "plt.imshow((x_pred[0]*255.0).astype('uint8'))\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Reconstructed Image')\n",
    "# 121 stands for (1 row, 2 columns, 2nd plot in the grid)\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_train[n].astype('uint8'))\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Convolution Auto Encoders\n",
    "Now we shall create an image dataset where random squares in images are removed.\n",
    "The autoencoder learns to fill these patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(inp_img):\n",
    "    crop_img = inp_img.copy()\n",
    "    x1 = np.random.randint(0, 15)\n",
    "    delta = np.random.randint(5, 10)\n",
    "    y1 = np.random.randint(0, 15)\n",
    "    crop_img[x1:x1+delta,y1:y1+delta,:] = 0.5\n",
    "    return(crop_img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot a random image and a clipped version of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = np.random.randint(0, high=50000)\n",
    "\n",
    "x_orig = x_train[n]\n",
    "x_crop = crop_image(x_orig)\n",
    "plt.subplot(121)\n",
    "plt.imshow(x_orig, cmap='gray_r')\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_crop, cmap='gray_r')\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Cropped Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dataset creation\n",
    "x_cropped = np.array(map(crop_image, x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cropped.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model training\n",
    "## We shall continue training from the previous autoencoder.\n",
    "model.fit(x_cropped/255.0, x_train/255.0, epochs=5, callbacks=[lrs], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "n = np.random.randint(0, high=50000)\n",
    "x_pred = model.predict(np.array([x_cropped[n]/255.0]), verbose=0)\n",
    "x_pred.shape\n",
    "plt.subplot(151)\n",
    "plt.imshow(x_train[n])\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(153)\n",
    "plt.imshow(x_cropped[n])\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Cropped Image')\n",
    "plt.subplot(155)\n",
    "plt.imshow((x_pred[0]*255.0).astype('uint8'))\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.title('Reconstructed Image')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
