{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re #importing os - operating system, re for regular expressions\n",
    "import pandas as pd #to work on data manipulataions \n",
    "import numpy as np #to do numerical calliculations \n",
    "cwd = os.chdir('E:/VINOD KUMAR/Project_Guf_new/Train_Test_Data')\n",
    "cwd #setting working directory\n",
    "import nltk # to preprocess the text we use Natural language tool kit \n",
    "from nltk.tokenize import sent_tokenize,word_tokenize  # To break docment to sentences\n",
    "import rtfConverter as rtf #user defined library to clear all meta data\n",
    "# this is to make sure we get no unicode based errors\n",
    "from __future__ import unicode_literals\n",
    "from  collections import Counter  # To count the values in our dataframe\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop deprecation warnings from being printed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy\n",
    "import spacy\n",
    "import en_core_web_sm \n",
    "nlp2= en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "pool = multiprocessing.Pool(processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import cross_validation,linear_model\n",
    "from sklearn.svm import LinearSVC,NuSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Test data file exists\n"
     ]
    }
   ],
   "source": [
    "# read the files if exists in working directory\n",
    "if (os.path.exists(\"Train_data.xlsx\"))==True & (os.path.exists(\"Test_data.xlsx\"))==True:\n",
    "    print(\"Train,Test data file exists\")\n",
    "    #print(\"Files in directory are:\",os.listdir(cwd))\n",
    "    #reading training data into a dataframe using pandas\n",
    "    actual_data=pd.read_excel(\"Train_data.xlsx\")\n",
    "    test_data=pd.read_excel(\"Test_data.xlsx\")\n",
    "       \n",
    "else: \n",
    "    print(\"file not exists\")\n",
    "    print(\"Files in directory are:\",os.listdir(cwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86554 entries, 0 to 86553\n",
      "Data columns (total 16 columns):\n",
      "FileID                  86554 non-null int64\n",
      "clientid                86554 non-null int64\n",
      "PID                     82817 non-null float64\n",
      "SUMMARY                 83731 non-null object\n",
      "DATA                    86554 non-null object\n",
      "Categories1             86554 non-null object\n",
      "Sub_categories1         86554 non-null object\n",
      "Categories2             1 non-null object\n",
      "Sub_categories2         0 non-null float64\n",
      "Categories3             0 non-null float64\n",
      "Sub_categories3         0 non-null float64\n",
      "Categories4             0 non-null float64\n",
      "Sub_categories4         0 non-null float64\n",
      "Categories5             0 non-null float64\n",
      "Sub_categories5         0 non-null float64\n",
      "Previous_Appointment    86554 non-null object\n",
      "dtypes: float64(8), int64(2), object(6)\n",
      "memory usage: 10.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1839 entries, 0 to 1838\n",
      "Data columns (total 16 columns):\n",
      "FileID                  1839 non-null int64\n",
      "clientid                1839 non-null int64\n",
      "PID                     1839 non-null int64\n",
      "SUMMARY                 1758 non-null object\n",
      "DATA                    1839 non-null object\n",
      "Categories1             1839 non-null object\n",
      "Sub_categories1         1839 non-null object\n",
      "Categories2             0 non-null float64\n",
      "Sub_categories2         0 non-null float64\n",
      "Categories3             0 non-null float64\n",
      "Sub_categories3         0 non-null float64\n",
      "Categories4             0 non-null float64\n",
      "Sub_categories4         0 non-null float64\n",
      "Categories5             0 non-null float64\n",
      "Sub_categories5         0 non-null float64\n",
      "Previous_Appointment    1839 non-null object\n",
      "dtypes: float64(8), int64(3), object(5)\n",
      "memory usage: 230.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(actual_data.info())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of missing values actual_data: 698991 FileID                      0\n",
      "clientid                    0\n",
      "PID                      3737\n",
      "SUMMARY                  2823\n",
      "DATA                        0\n",
      "Categories1                 0\n",
      "Sub_categories1             0\n",
      "Categories2             86553\n",
      "Sub_categories2         86554\n",
      "Categories3             86554\n",
      "Sub_categories3         86554\n",
      "Categories4             86554\n",
      "Sub_categories4         86554\n",
      "Categories5             86554\n",
      "Sub_categories5         86554\n",
      "Previous_Appointment        0\n",
      "dtype: int64\n",
      "No of missing values test_data: 14793 FileID                     0\n",
      "clientid                   0\n",
      "PID                        0\n",
      "SUMMARY                   81\n",
      "DATA                       0\n",
      "Categories1                0\n",
      "Sub_categories1            0\n",
      "Categories2             1839\n",
      "Sub_categories2         1839\n",
      "Categories3             1839\n",
      "Sub_categories3         1839\n",
      "Categories4             1839\n",
      "Sub_categories4         1839\n",
      "Categories5             1839\n",
      "Sub_categories5         1839\n",
      "Previous_Appointment       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"No of missing values actual_data:\",sum(actual_data.isnull().sum()), (actual_data.isnull().sum()))\n",
    "print(\"No of missing values test_data:\",sum(test_data.isnull().sum()),(test_data.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We observed Train data has 10.6 MB data with 86554 rows and 16 columns, \n",
    "# Test data has 428 KB data, 3427 rows and 16 columns.\n",
    "# We can observe that in \"SUMMARY\" column of train data has missing values\n",
    "# We observe that 8 columns in both the tables doesn't have any value init so we can ignore them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting datatype of actual_data1 variables \n",
    "actual_data.SUMMARY =actual_data.SUMMARY.astype('str')\n",
    "actual_data.DATA =actual_data.DATA.astype('str')\n",
    "actual_data.Categories1=actual_data.Categories1.astype(\"category\")\n",
    "actual_data.Sub_categories1=actual_data.Sub_categories1.astype(\"category\")\n",
    "actual_data.Previous_Appointment=actual_data.Previous_Appointment.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting datatype of actual_data1 variables \n",
    "test_data.SUMMARY =test_data.SUMMARY.astype('str')\n",
    "test_data.DATA =test_data.DATA.astype('str')\n",
    "test_data.Categories1=test_data.Categories1.astype(\"category\")\n",
    "test_data.Sub_categories1=test_data.Sub_categories1.astype(\"category\")\n",
    "test_data.Previous_Appointment=test_data.Previous_Appointment.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>clientid</th>\n",
       "      <th>PID</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>DATA</th>\n",
       "      <th>Categories1</th>\n",
       "      <th>Sub_categories1</th>\n",
       "      <th>Categories2</th>\n",
       "      <th>Sub_categories2</th>\n",
       "      <th>Categories3</th>\n",
       "      <th>Sub_categories3</th>\n",
       "      <th>Categories4</th>\n",
       "      <th>Sub_categories4</th>\n",
       "      <th>Categories5</th>\n",
       "      <th>Sub_categories5</th>\n",
       "      <th>Previous_Appointment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92824</td>\n",
       "      <td>1004</td>\n",
       "      <td>1.750262e+15</td>\n",
       "      <td>nan</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>MEDICATION RELATED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92825</td>\n",
       "      <td>1004</td>\n",
       "      <td>1.583836e+15</td>\n",
       "      <td>recurrent chest wall pain pneumonia symptoms</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>SYMPTOMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92826</td>\n",
       "      <td>1004</td>\n",
       "      <td>1.583837e+15</td>\n",
       "      <td>nan</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>MEDICATION RELATED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92827</td>\n",
       "      <td>1004</td>\n",
       "      <td>1.583837e+15</td>\n",
       "      <td>nan</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>PRESCRIPTION</td>\n",
       "      <td>REFILL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92828</td>\n",
       "      <td>1004</td>\n",
       "      <td>1.583837e+15</td>\n",
       "      <td>nan</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>PRESCRIPTION</td>\n",
       "      <td>REFILL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FileID  clientid           PID  \\\n",
       "0   92824      1004  1.750262e+15   \n",
       "1   92825      1004  1.583836e+15   \n",
       "2   92826      1004  1.583837e+15   \n",
       "3   92827      1004  1.583837e+15   \n",
       "4   92828      1004  1.583837e+15   \n",
       "\n",
       "                                        SUMMARY  \\\n",
       "0                                           nan   \n",
       "1  recurrent chest wall pain pneumonia symptoms   \n",
       "2                                           nan   \n",
       "3                                           nan   \n",
       "4                                           nan   \n",
       "\n",
       "                                                DATA   Categories1  \\\n",
       "0  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "1  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "2  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "3  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  PRESCRIPTION   \n",
       "4  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  PRESCRIPTION   \n",
       "\n",
       "      Sub_categories1 Categories2  Sub_categories2  Categories3  \\\n",
       "0  MEDICATION RELATED         NaN              NaN          NaN   \n",
       "1            SYMPTOMS         NaN              NaN          NaN   \n",
       "2  MEDICATION RELATED         NaN              NaN          NaN   \n",
       "3              REFILL         NaN              NaN          NaN   \n",
       "4              REFILL         NaN              NaN          NaN   \n",
       "\n",
       "   Sub_categories3  Categories4  Sub_categories4  Categories5  \\\n",
       "0              NaN          NaN              NaN          NaN   \n",
       "1              NaN          NaN              NaN          NaN   \n",
       "2              NaN          NaN              NaN          NaN   \n",
       "3              NaN          NaN              NaN          NaN   \n",
       "4              NaN          NaN              NaN          NaN   \n",
       "\n",
       "   Sub_categories5 Previous_Appointment  \n",
       "0              NaN                   No  \n",
       "1              NaN                   No  \n",
       "2              NaN                   No  \n",
       "3              NaN                   No  \n",
       "4              NaN                   No  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>clientid</th>\n",
       "      <th>PID</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>DATA</th>\n",
       "      <th>Categories1</th>\n",
       "      <th>Sub_categories1</th>\n",
       "      <th>Categories2</th>\n",
       "      <th>Sub_categories2</th>\n",
       "      <th>Categories3</th>\n",
       "      <th>Sub_categories3</th>\n",
       "      <th>Categories4</th>\n",
       "      <th>Sub_categories4</th>\n",
       "      <th>Categories5</th>\n",
       "      <th>Sub_categories5</th>\n",
       "      <th>Previous_Appointment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201291</td>\n",
       "      <td>1004</td>\n",
       "      <td>1694340834006680</td>\n",
       "      <td>BP concerns</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>APPOINTMENTS</td>\n",
       "      <td>NEW APPOINTMENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201292</td>\n",
       "      <td>1004</td>\n",
       "      <td>1583836598100010</td>\n",
       "      <td>S/e Cymbalta</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>MEDICATION RELATED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201293</td>\n",
       "      <td>1004</td>\n",
       "      <td>1772030862984470</td>\n",
       "      <td>****Ask Dr. R-back pain what do you recommend?</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>MEDICATION RELATED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201295</td>\n",
       "      <td>1004</td>\n",
       "      <td>1709735526006510</td>\n",
       "      <td>Sinus infection</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>SYMPTOMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201298</td>\n",
       "      <td>1004</td>\n",
       "      <td>1583836937250010</td>\n",
       "      <td>FYI for Dr. Russo</td>\n",
       "      <td>{\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...</td>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>SYMPTOMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FileID  clientid               PID  \\\n",
       "0  201291      1004  1694340834006680   \n",
       "1  201292      1004  1583836598100010   \n",
       "2  201293      1004  1772030862984470   \n",
       "3  201295      1004  1709735526006510   \n",
       "4  201298      1004  1583836937250010   \n",
       "\n",
       "                                          SUMMARY  \\\n",
       "0                                     BP concerns   \n",
       "1                                    S/e Cymbalta   \n",
       "2  ****Ask Dr. R-back pain what do you recommend?   \n",
       "3                                 Sinus infection   \n",
       "4                               FYI for Dr. Russo   \n",
       "\n",
       "                                                DATA   Categories1  \\\n",
       "0  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  APPOINTMENTS   \n",
       "1  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "2  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "3  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "4  {\\rtf1\\ansi\\ftnbj{\\fonttbl{\\f0 \\fswiss Arial;}...  ASK_A_DOCTOR   \n",
       "\n",
       "      Sub_categories1  Categories2  Sub_categories2  Categories3  \\\n",
       "0     NEW APPOINTMENT          NaN              NaN          NaN   \n",
       "1  MEDICATION RELATED          NaN              NaN          NaN   \n",
       "2  MEDICATION RELATED          NaN              NaN          NaN   \n",
       "3            SYMPTOMS          NaN              NaN          NaN   \n",
       "4            SYMPTOMS          NaN              NaN          NaN   \n",
       "\n",
       "   Sub_categories3  Categories4  Sub_categories4  Categories5  \\\n",
       "0              NaN          NaN              NaN          NaN   \n",
       "1              NaN          NaN              NaN          NaN   \n",
       "2              NaN          NaN              NaN          NaN   \n",
       "3              NaN          NaN              NaN          NaN   \n",
       "4              NaN          NaN              NaN          NaN   \n",
       "\n",
       "   Sub_categories5 Previous_Appointment  \n",
       "0              NaN                   No  \n",
       "1              NaN                   No  \n",
       "2              NaN                   No  \n",
       "3              NaN                   No  \n",
       "4              NaN                   No  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to clean DATA,SUMMARY column to bulid our model - so we use NLTK,Regular expressions for cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writen a function to call rtf file to extract data from meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction to extract text from rtf file \n",
    "def sentence_extraction(doc):\n",
    "    text = rtf.striprtf(doc)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.1 s\n"
     ]
    }
   ],
   "source": [
    "%time actual_data[\"extracted_train_doc\"] = [sentence_extraction(actual_data.DATA[i]) for i in range(0,len(actual_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%time test_data[\"extracted_test_doc\"] = [sentence_extraction(test_data.DATA[i]) for i in range(0,len(test_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of missing values actual_data: 0\n",
      "No of missing values test_data: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"No of missing values actual_data:\",sum(actual_data.extracted_train_doc.isnull()))\n",
    "print(\"No of missing values test_data:\",sum(test_data.extracted_test_doc.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for extracting original data from meta it took 50.2 secs for train data, 2.01 secs for test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phone Note \\nCall from Patient\\nCall back at 693-9559\\nCaller: Sherrie, wife\\nInitial call taken by: Melissa Dykes CMA,  February 22, 2016 2:31 PM\\nSummary of Call: He needs to be seen by Dr. Shaw.  He had cold/flu about a month ago.  He has had a chronic cough since.  He would like a 9 or 10:00 appt this week.  You can leave the appt info on my VM.  He does not want to see the NP again\\n\\n\\nFollow-up for Phone Call \\nMD Followup Details: Confirm that he is taking Dexilant (reflux related cough).  Ok to schedule OV with me when available.\\n \\nFollow-up by: William D Shaw MD,  February 22, 2016 3:07 PM\\nClinical Followup Details: left message with wife, she will call husband and let me know......................................Kelly Sykes  CNA  February 22, 2016 3:18 PM \\n\\nwife said that she will get back in touch with us ......................................Kelly Sykes  CNA  February 23, 2016 1:44 PM \\nAction Taken: Phone Call Completed\\nFollow-up by: Kelly Sykes  CNA,  February 23, 2016 1:44 PM\\n\\n\\n \\n\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data[\"extracted_train_doc\"][5500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Phone Note \\nCall from Patient\\nCaller: Patient\\nInitial call taken by: Ashley Cross, RN,  June  1, 2018 8:37 AM\\nSummary of Call: Patient called and said he was lifting heavy bag of concrete on Monday and he is c/o back pain on left side in his lower back and muscle spasms and it hurts to inhale so he wants to know what we recommend? Patient said this has happend to before but it hasn't lasted this long and he been taking Ibuprofen and it has helped some and he wants to knwo what we recommend?\\n\\nNew Medications:\\nCYCLOBENZAPRINE HCL 10 MG ORAL TABLET (CYCLOBENZAPRINE HCL) ONE PO BID prn\\nNew Medications:\\nCYCLOBENZAPRINE HCL 10 MG ORAL TABLET (CYCLOBENZAPRINE HCL) ONE PO BID prn\\n\\nFollow-up for Phone Call \\nMD Followup Details: Can do heat, message, and we can call in Muscle Relaers.\\nFlexeril 10 mg PO BID prn #14.\\nIf does not help or he is in Sig pain - issues - then get seen\\n \\nFollow-up by: John M Russo MD,  June  1, 2018 10:22 AM\\nClinical Followup Details: walgreens cornwalis \\n\\nSpoke with pt and advised him of above .....................................Kelly Sykes  MA  June  1, 2018 10:25 AM \\nAction Taken: Phone Call Completed\\nFollow-up by: Kelly Sykes  MA,  June  1, 2018 10:25 AM\\n\\nNew Medications:\\nCYCLOBENZAPRINE HCL 10 MG ORAL TABLET (CYCLOBENZAPRINE HCL) ONE PO BID prn\\n\\n \""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_data[\"extracted_test_doc\"][2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def clean_str2(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    #string = re.sub(r'\\b[A-Z]+\\b', '', string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"Phone Note \", \" \", string)\n",
    "    string = re.sub(r\"Summary of Call \", \" \", string)\n",
    "    string = re.sub(r\"New Medications\", \" \", string)\n",
    "    string = re.sub(r\"New Allergies \", \" \", string)\n",
    "    string = re.sub(r\"Call from Patient \", \" \", string)\n",
    "    string = re.sub(r\"Clinical Followup Details \", \" \", string)\n",
    "    string = re.sub(r\"Caller \", \" \", string)\n",
    "    string = re.sub(r\"Initial call taken by \", \" \", string)\n",
    "    string = re.sub(r\"Followup Details \", \" \", string)\n",
    "    string = re.sub(r\"Follow-up by \", \" \", string)\n",
    "    string = re.sub(r\"Call back at \", \" \", string)\n",
    "    string = re.sub(r\"Call from Other Clinic \", \" \", string)\n",
    "    string = re.sub(r\"Home Phone \", \" \", string)\n",
    "    string = re.sub(r\"Converted from flag \", \" \", string)\n",
    "    #string = re.sub(r\"Call from Pharmacy \", \" \", string)\n",
    "    string = re.sub(r\"Prescriptions \", \" \", string)\n",
    "    string = re.sub(r\"Entered by \", \" \", string)\n",
    "    string = re.sub(r\"Authorized by \", \" \", string)\n",
    "    string = re.sub(r\"Electronically signed by\", \" \", string)\n",
    "    string = re.sub(r\"Method used \", \" \", string)\n",
    "    string = re.sub(r\"AM \", \" \", string)\n",
    "    string = re.sub(r\"PM \", \" \", string)\n",
    "    #string = re.sub(r\"Ph \", \" \", string)\n",
    "    #string = re.sub(r\"Fax \", \" \", string)\n",
    "    #string = re.sub(r\"RxID \", \" \", string)\n",
    "    string = re.sub(r\"Work Phone \", \" \", string)\n",
    "    string = re.sub(r\"New Orders wrote\", \" \", string)\n",
    "    #string = re.sub(r\"wrote\", \" \", string)\n",
    "    string = re.sub(r\"Action Taken \", \" \", string)\n",
    "    string = re.sub(r\"To Whom It May Concern \", \" \", string)\n",
    "    string = re.sub(r\"Follow up for Phone Call \", \" \", string)\n",
    "    string = re.sub(r\"Phone Call Completed \", \" \", string)\n",
    "    string = re.sub(r\"Follow up by\", \" \", string)\n",
    "    string = re.sub(r\"Other Incoming Call \",\" \", string)\n",
    "    review_text = string.strip()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    return letters_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patient  Shanon Wright CMA   February                  At the audiologist and needs a referral Dr Steinmark Fax          Phone          New Problems Hearing loss    ICD             ICD   H         New Orders Consult Audiology Hearing Con AH New Problems Hearing loss    ICD             ICD   H         New Orders Consult Audiology Hearing Con AH'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_str2(actual_data[\"extracted_train_doc\"][5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patient  Shanon Wright CMA   February                  At the audiologist and needs a referral Dr Steinmark Fax          Phone          New Problems Hearing loss    ICD             ICD   H         New Orders Consult Audiology Hearing Con AH New Problems Hearing loss    ICD             ICD   H         New Orders Consult Audiology Hearing Con AH'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_str2(actual_data[\"extracted_train_doc\"][5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone Note \n",
      "Call from Patient\n",
      "Call back at 394-4332\n",
      "Caller: Patient\n",
      "Initial call taken by: Amanda Gray,  February 12, 2016 11:20 AM\n",
      "Summary of Call: I have lost control of my bladder. Incontience. It's every hour. \n",
      "\n",
      "New Medications:\n",
      "CIPRO 250 MG ORAL TABS (CIPROFLOXACIN HCL) 1 po bid\n",
      "New Medications:\n",
      "CIPRO 250 MG ORAL TABS (CIPROFLOXACIN HCL) 1 po bid\n",
      "\n",
      "Follow-up for Phone Call \n",
      "MD Followup Details: may leave sample in lab if wants.\n",
      "\n",
      "okay to treat for uti.\n",
      "\n",
      "cipro 250 mg one po bid #10\n",
      "take align( over the counter) one daily for 2 weeks as a probiotic\n",
      "keep hydrated.\n",
      "thank you\n",
      "\n",
      " \n",
      "Follow-up by: Mark A Perini MD,  February 12, 2016 11:27 AM\n",
      "Clinical Followup Details: Patient was directly notified and RX was e-scribed/called to the pharmacy....................................Amanda Gray  February 12, 2016 11:43 AM \n",
      "\n",
      "New Medications:\n",
      "CIPRO 250 MG ORAL TABS (CIPROFLOXACIN HCL) 1 po bid\n",
      "\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(actual_data[\"extracted_train_doc\"][4550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Names,Time, Days, Months, Years, Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phone Note \\nCall from Patient\\nInitial call taken by: John M Russo MD,  January  1, 2016 1:38 PM\\nSummary of Call: called today c ST/cough, congestion, Head congestion, + fever, Severe nasal issues. Seems like Sinusitis.\\nNot flu like\\nCannot take mucinex for ??\\nOK for plain old Guafen DM\\n\\n\\n\\nNew Medications:\\nBENZONATATE 200 MG ORAL CAPS (BENZONATATE) one PO TID prn cough\\nCEFDINIR 300 MG ORAL CAPS (CEFDINIR) one po BID\\nNew Medications:\\nBENZONATATE 200 MG ORAL CAPS (BENZONATATE) one PO TID prn cough\\nCEFDINIR 300 MG ORAL CAPS (CEFDINIR) one po BID\\n \\nFollow-up by: John M Russo MD,  January  1, 2016 1:39 PM\\n\\nNew Medications:\\nBENZONATATE 200 MG ORAL CAPS (BENZONATATE) one PO TID prn cough\\nCEFDINIR 300 MG ORAL CAPS (CEFDINIR) one po BID\\n\\n \\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data[\"extracted_train_doc\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John M Russo MD   January                 called today c ST cough   congestion   Head congestion   fever   Severe nasal issues Seems like Sinusitis Not flu like Cannot take mucinex for       OK for plain old Guafen DM   BENZONATATE     MG ORAL CAPS    BENZONATATE    one PO TID prn cough CEFDINIR     MG ORAL CAPS    CEFDINIR    one po BID   BENZONATATE     MG ORAL CAPS    BENZONATATE    one PO TID prn cough CEFDINIR     MG ORAL CAPS    CEFDINIR    one po BID   John M Russo MD   January                  BENZONATATE     MG ORAL CAPS    BENZONATATE    one PO TID prn cough CEFDINIR     MG ORAL CAPS    CEFDINIR    one po BID'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_str2(actual_data[\"extracted_train_doc\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John M Russo MD  January  1, 2016 1:38 PM \n",
      " Summary today Severe Sinusitis \n",
      " \n",
      " \n",
      " Guafen DM New Medications \n",
      " BENZONATATE 200 MG ORAL one PO TID \n",
      " 300 CAPS CEFDINIR one \n",
      " BENZONATATE 200 MG ORAL one PO TID \n",
      " 300 CAPS CEFDINIR one John M Russo MD  January  1, 2016 1:39 PM \n",
      " BENZONATATE 200 MG ORAL one PO TID \n",
      " 300 CAPS CEFDINIR one\n"
     ]
    }
   ],
   "source": [
    "d=(' '.join(map(str,nlp2((actual_data[\"extracted_train_doc\"][2])).ents))).split(\" \")\n",
    "print(\" \".join(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John M Russo January today            Severe Sinusitis Not        Guafen DM BENZONATATE MG ORAL one PO TID CEFDINIR     MG ORAL CAPS CEFDINIR one MG ORAL one PO TID CEFDINIR     MG ORAL CAPS CEFDINIR one John M Russo January                   BENZONATATE one PO TID CEFDINIR     MG ORAL CAPS CEFDINIR one\n"
     ]
    }
   ],
   "source": [
    "d=(' '.join(map(str,nlp2(clean_str2(actual_data[\"extracted_train_doc\"][2])).ents))).split(\" \")\n",
    "print(\" \".join(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone Note \n",
      "Call from Patient\n",
      "Initial call taken by: John M Russo MD,  January  1, 2016 1:38 PM\n",
      "Summary of Call: called today c ST/cough, congestion, Head congestion, + fever, Severe nasal issues. Seems like Sinusitis.\n",
      "Not flu like\n",
      "Cannot take mucinex for ??\n",
      "OK for plain old Guafen DM\n",
      "\n",
      "\n",
      "\n",
      "New Medications:\n",
      "BENZONATATE 200 MG ORAL CAPS (BENZONATATE) one PO TID prn cough\n",
      "CEFDINIR 300 MG ORAL CAPS (CEFDINIR) one po BID\n",
      "New Medications:\n",
      "BENZONATATE 200 MG ORAL CAPS (BENZONATATE) one PO TID prn cough\n",
      "CEFDINIR 300 MG ORAL CAPS (CEFDINIR) one po BID\n",
      " \n",
      "Follow-up by: John M Russo MD,  January  1, 2016 1:39 PM\n",
      "\n",
      "New Medications:\n",
      "BENZONATATE 200 MG ORAL CAPS (BENZONATATE) one PO TID prn cough\n",
      "CEFDINIR 300 MG ORAL CAPS (CEFDINIR) one po BID\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "John M Russo January today            Severe Sinusitis Not        Guafen DM BENZONATATE MG ORAL one PO TID CEFDINIR     MG ORAL CAPS CEFDINIR one MG ORAL one PO TID CEFDINIR     MG ORAL CAPS CEFDINIR one John M Russo January                   BENZONATATE one PO TID CEFDINIR     MG ORAL CAPS CEFDINIR one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MD called c ST cough congestion Head congestion fever nasal issues Seems like flu like Can not take mucinex for OK for plain old prn cough po BID prn cough po BID MD prn cough po BID'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(actual_data[\"extracted_train_doc\"][2])\n",
    "d=(' '.join(map(str,nlp2(clean_str2(actual_data[\"extracted_train_doc\"][2])).ents))).split(\" \")\n",
    "print(\" \".join(d))\n",
    "word_tokens = word_tokenize(clean_str2(actual_data[\"extracted_train_doc\"][2]))\n",
    "word_tokens\n",
    "filtered_sentence =[w for w in word_tokens if not w in d]\n",
    "\" \".join([w for w in word_tokens if not w in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#spacy=[]\n",
    "#for i in range (0,len(actual_data)):\n",
    "#    if i%1000 == 0:\n",
    "#        print (\"no.of rows reviews processed:\",i)\n",
    "#    spacy.append(' '.join(map(str,nlp2(actual_data[\"extracted_train_doc\"][i]).ents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_test=[]\n",
    "#for i in range (0,len(test_data)):\n",
    "#    if i%1000 == 0:\n",
    "#        print (\"no.of rows reviews processed:\",i)\n",
    "#    spacy_test.append(' '.join(map(str,nlp2(test_data[\"extracted_test_doc\"][i]).ents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time actual_data[\"scapy\"]=pd.DataFrame(spacy)\n",
    "#%time test_data[\"scapy\"]=pd.DataFrame(spacy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 0\n",
      "no.of rows reviews processed: 10000\n",
      "no.of rows reviews processed: 20000\n",
      "no.of rows reviews processed: 30000\n",
      "no.of rows reviews processed: 40000\n",
      "no.of rows reviews processed: 50000\n",
      "no.of rows reviews processed: 60000\n",
      "no.of rows reviews processed: 70000\n",
      "no.of rows reviews processed: 80000\n",
      "Training took 1775.097 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "spacy_sent=[]\n",
    "for i in range (0,len(actual_data)):\n",
    "    if i%10000 == 0:\n",
    "        print (\"no.of rows reviews processed:\",i)\n",
    "    d=(' '.join(map(str,nlp2(clean_str2(actual_data[\"extracted_train_doc\"][i])).ents))).split(\" \")\n",
    "    word_tokens = word_tokenize(clean_str2(actual_data[\"extracted_train_doc\"][i]))\n",
    "    spacy_sent.append(\" \".join([w for w in word_tokens if not w in d]))\n",
    "print(\"Training took {:0.3f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 0\n",
      "no.of rows reviews processed: 1000\n",
      "Training took 37.730 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "spacy_test_sent=[]\n",
    "for i in range (0,len(test_data)):\n",
    "    if i%1000 == 0:\n",
    "        print (\"no.of rows reviews processed:\",i)\n",
    "    d=(' '.join(map(str,nlp2(clean_str2(test_data[\"extracted_test_doc\"][i])).ents))).split(\" \")\n",
    "    word_tokens = word_tokenize(clean_str2(test_data[\"extracted_test_doc\"][i]))\n",
    "    spacy_test_sent.append(\" \".join([w for w in word_tokens if not w in d]))\n",
    "print(\"Training took {:0.3f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.1 ms\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time actual_data[\"spacy_sent\"]=pd.DataFrame(spacy_sent)\n",
    "%time test_data[\"spacy_test_sent\"]=pd.DataFrame(spacy_test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 ms\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time actual_data[\"spacy_sent\"]= actual_data[\"spacy_sent\"].astype(str)\n",
    "%time test_data[\"spacy_test_sent\"]=test_data[\"spacy_test_sent\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We switched to She is out of her triam hctz TABS take TABS take Patient was directly notified and RX was e scribed called to the pharmacy TABS take'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data[\"spacy_sent\"][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining SUMMARY column with Spacy_sentences\n",
    "actual_data['combined_sent'] = actual_data['SUMMARY'].map(str) +\" \" +actual_data['spacy_sent']\n",
    "test_data['combined_sent'] = test_data['SUMMARY'].map(str) +\" \" +test_data['spacy_test_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data['combined_sent'] = actual_data['combined_sent'].astype(str)\n",
    "test_data['combined_sent'] = test_data['combined_sent'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nan Some better c cough and congestion However...\n",
       "1    recurrent chest wall pain pneumonia symptoms R...\n",
       "2    nan MD called c ST cough congestion Head conge...\n",
       "3    nan Needs something stronger for cough than OT...\n",
       "4    nan MD She called to get refill on mg x for br...\n",
       "Name: combined_sent, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data['combined_sent'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time actual_data.to_csv(\"actual_data_2.csv\",index=False)\n",
    "#%time test_data.to_csv(\"test_data_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some Preprocessing\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def raw_to_prepwithtokenize( raw_review ):\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    low_case = letters_only.lower()\n",
    "    words = nltk.word_tokenize(low_case)\n",
    "    stops = set(stopwords.words(\"english\")+[\"pm\",'nan',\"am\",\"aa\",\"trimethoprim\",\"sulfamethoxanole\",\n",
    "                                            \"fyi\",\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\n",
    "                                            \"october\",\"november\",\"december\"])                  \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    processed_sentence = \" \".join(meaningful_words)\n",
    "    return(processed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 10000\n",
      "no.of rows reviews processed: 20000\n",
      "no.of rows reviews processed: 30000\n",
      "no.of rows reviews processed: 40000\n",
      "no.of rows reviews processed: 50000\n",
      "no.of rows reviews processed: 60000\n",
      "no.of rows reviews processed: 70000\n",
      "no.of rows reviews processed: 80000\n"
     ]
    }
   ],
   "source": [
    "process=[]\n",
    "for i in range (0,len(actual_data)):\n",
    "    if i%10000 == 0:\n",
    "        print (\"no.of rows reviews processed:\",i)\n",
    "    process.append(raw_to_prepwithtokenize(actual_data['combined_sent'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 1000\n"
     ]
    }
   ],
   "source": [
    "process_test=[]\n",
    "for i in range (0,len(test_data)):\n",
    "    if i%1000 == 0:\n",
    "        print (\"no.of rows reviews processed:\",i)\n",
    "    process_test.append(raw_to_prepwithtokenize(test_data['combined_sent'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data[\"processed_combined_sent\"]=pd.DataFrame(process)\n",
    "test_data[\"processed_combined_sent\"]=pd.DataFrame(process_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r q lyrica cma reason details lot walking lot burning foot like try rx pregabalin po qhs pregabalin po qhs sound ok mg ref called patient notified patient rx called cma pregabalin po qhs'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data[\"processed_combined_sent\"][10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "words = stopwords.words(\"english\")\n",
    "actual_data['processed_combined_sent'] = actual_data['processed_combined_sent'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "test_data['processed_combined_sent'] = test_data['processed_combined_sent'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    better c cough congest howev still c low grade...\n",
       "1    recurr chest wall pain pneumonia symptom ravis...\n",
       "2    md call c st cough congest head congest fever ...\n",
       "3    need someth stronger cough otc call cap po prn...\n",
       "4    md call get refil mg x bronchiti cough congest...\n",
       "Name: processed_combined_sent, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data['processed_combined_sent'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86554"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_data['combined_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27733"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each word frequency count in Whole Corpus\n",
    "freq_count_data = pd.Series(' '.join(actual_data[\"processed_combined_sent\"]).split()).value_counts()\n",
    "len(freq_count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient       96281\n",
       "call          90555\n",
       "cma           68592\n",
       "take          66513\n",
       "need          65128\n",
       "pt            61733\n",
       "dr            49896\n",
       "tab           39346\n",
       "said          33541\n",
       "want          33370\n",
       "rx            31953\n",
       "back          31021\n",
       "get           30418\n",
       "notifi        30105\n",
       "appt          30047\n",
       "mouth         29113\n",
       "mg            27170\n",
       "tablet        25880\n",
       "pain          24156\n",
       "x             23784\n",
       "know          22878\n",
       "see           22821\n",
       "would         21697\n",
       "advis         20872\n",
       "day           20696\n",
       "cough         19565\n",
       "refil         18819\n",
       "done          18819\n",
       "go            18811\n",
       "n             18461\n",
       "              ...  \n",
       "longt             1\n",
       "plea              1\n",
       "dehydar           1\n",
       "junamet           1\n",
       "meantin           1\n",
       "senario           1\n",
       "atena             1\n",
       "amlopidin         1\n",
       "amioradon         1\n",
       "snowi             1\n",
       "theshold          1\n",
       "bisacodyl         1\n",
       "affor             1\n",
       "disfigur          1\n",
       "boht              1\n",
       "abe               1\n",
       "evalatuion        1\n",
       "cefdiniur         1\n",
       "hpc               1\n",
       "lakeland          1\n",
       "thaought          1\n",
       "instrument        1\n",
       "vberbal           1\n",
       "deanna            1\n",
       "staomch           1\n",
       "nfo               1\n",
       "rigid             1\n",
       "allergc           1\n",
       "cruri             1\n",
       "reestb            1\n",
       "Length: 27733, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27733.000000\n",
       "mean       129.330112\n",
       "std       1527.201430\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          7.000000\n",
       "max      96281.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_count_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK_A_DOCTOR     31337\n",
      "PRESCRIPTION     21490\n",
      "APPOINTMENTS     19477\n",
      "MISCELLANEOUS    10848\n",
      "LAB               3402\n",
      "Name: Categories1, dtype: int64 AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGKCAYAAAD+C2MGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xu4ZFV95//3R26igKA2hGlQ0LSRiwLaIqMTRyEB1BggyghqIIafRAMTzU8zQROD9+g4hgTHS3AgthkjEqOBGAwySOIdaS4CDRJaEGgh0goiSBDB7/yx9xnKpvpyTtc5u88679fz1HN2rb2rzvfU012fWnuvWitVhSRJasPDhi5AkiRNjsEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJasjmQxcwU4997GNrt912G7oMSZLmxCWXXPL9qlq0vuPmbbDvtttuLF++fOgyJEmaE0lu3JDjPBUvSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJaojBLklSQwx2SZIaYrBLktSQeTtXvOaxtzxq6Aqm7y13Dl2BJG0Qe+ySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1JD1BnuShyf5RpJvJlmR5K19++5JLkpyXZJPJtmyb9+qv7+y37/byHO9sW+/NskhI+2H9m0rk5w0+T9TkqSFYUN67D8BDqyqfYB9gUOTHAC8BzilqpYAdwDH9ccfB9xRVb8InNIfR5I9gaOAvYBDgQ8m2SzJZsAHgOcDewJH98dKkqRpWm+wV+fu/u4W/a2AA4FP9e3LgMP77cP6+/T7D0qSvv3MqvpJVd0ArAT2728rq+r6qroPOLM/VpIkTdMGXWPve9aXA7cB5wPfBn5YVff3h6wCFvfbi4GbAfr9dwKPGW1f4zFrax9Xx/FJlidZvnr16g0pXZKkBWWDgr2qHqiqfYFd6HrYe4w7rP+Zteybbvu4Ok6rqqVVtXTRokXrL1ySpAVmWqPiq+qHwD8DBwDbJ5laRGYX4JZ+exWwK0C//1HA7aPtazxmbe2SJGmaNmRU/KIk2/fbWwO/AlwDXAi8pD/sWODsfvuc/j79/i9UVfXtR/Wj5ncHlgDfAC4GlvSj7LekG2B3ziT+OEmSFpoNWbZ1Z2BZP3r9YcBZVfXZJFcDZyZ5B3AZcHp//OnAXydZSddTPwqgqlYkOQu4GrgfOKGqHgBIciJwHrAZcEZVrZjYXyhJ0gKy3mCvqiuA/ca0X093vX3N9nuBI9fyXO8E3jmm/Vzg3A2oV5IkrYMzz0mS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJaojBLklSQwx2SZIaYrBLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJaojBLklSQwx2SZIast5gT7JrkguTXJNkRZLX9u1vSfLdJJf3txeMPOaNSVYmuTbJISPth/ZtK5OcNNK+e5KLklyX5JNJtpz0HypJ0kKwIT32+4HXV9UewAHACUn27PedUlX79rdzAfp9RwF7AYcCH0yyWZLNgA8Azwf2BI4eeZ739M+1BLgDOG5Cf58kSQvKeoO9qm6tqkv77buAa4DF63jIYcCZVfWTqroBWAns399WVtX1VXUfcCZwWJIABwKf6h+/DDh8pn+QJEkL2bSusSfZDdgPuKhvOjHJFUnOSLJD37YYuHnkYav6trW1Pwb4YVXdv0b7uN9/fJLlSZavXr16OqVLkrQgbHCwJ9kG+DvgdVX1I+BDwBOBfYFbgfdNHTrm4TWD9oc2Vp1WVUuraumiRYs2tHRJkhaMzTfkoCRb0IX6x6vq0wBV9b2R/R8BPtvfXQXsOvLwXYBb+u1x7d8Htk+yed9rHz1ekiRNw4aMig9wOnBNVf3ZSPvOI4cdAVzVb58DHJVkqyS7A0uAbwAXA0v6EfBb0g2wO6eqCrgQeEn/+GOBszfuz5IkaWHakB77s4HfBK5Mcnnf9ia6Ue370p02/w7wOwBVtSLJWcDVdCPqT6iqBwCSnAicB2wGnFFVK/rn+0PgzCTvAC6j+yAhSZKmab3BXlVfZvx18HPX8Zh3Au8c037uuMdV1fV0o+YlSdJGcOY5SZIaYrBLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJasjmQxcgSdLafODVXxi6hGk74cMHDvr77bFLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGrLeYE+ya5ILk1yTZEWS1/btj05yfpLr+p879O1JcmqSlUmuSPK0kec6tj/+uiTHjrQ/PcmV/WNOTZLZ+GMlSWrdhvTY7wdeX1V7AAcAJyTZEzgJuKCqlgAX9PcBng8s6W/HAx+C7oMAcDLwTGB/4OSpDwP9McePPO7Qjf/TJElaeNYb7FV1a1Vd2m/fBVwDLAYOA5b1hy0DDu+3DwM+Vp2vA9sn2Rk4BDi/qm6vqjuA84FD+33bVdXXqqqAj408lyRJmoZpXWNPshuwH3ARsFNV3Qpd+AM79octBm4eediqvm1d7avGtEuSpGna4GBPsg3wd8DrqupH6zp0TFvNoH1cDccnWZ5k+erVq9dXsiRJC84GBXuSLehC/eNV9em++Xv9aXT6n7f17auAXUcevgtwy3radxnT/hBVdVpVLa2qpYsWLdqQ0iVJWlA2ZFR8gNOBa6rqz0Z2nQNMjWw/Fjh7pP2YfnT8AcCd/an684CDk+zQD5o7GDiv33dXkgP633XMyHNJkqRp2JD12J8N/CZwZZLL+7Y3Ae8GzkpyHHATcGS/71zgBcBK4B7glQBVdXuStwMX98e9rapu77dfA3wU2Br4XH+TJEnTtN5gr6ovM/46OMBBY44v4IS1PNcZwBlj2pcDe6+vlrmw20n/OHQJ0/add79w6BIkSZsIZ56TJKkhBrskSQ0x2CVJaojBLklSQwx2SZIaYrBLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJaojBLklSQwx2SZIaYrBLktQQg12SpIYY7JIkNcRglySpIesN9iRnJLktyVUjbW9J8t0kl/e3F4zse2OSlUmuTXLISPuhfdvKJCeNtO+e5KIk1yX5ZJItJ/kHSpK0kGxIj/2jwKFj2k+pqn3727kASfYEjgL26h/zwSSbJdkM+ADwfGBP4Oj+WID39M+1BLgDOG5j/iBJkhay9QZ7VX0RuH0Dn+8w4Myq+klV3QCsBPbvbyur6vqqug84EzgsSYADgU/1j18GHD7Nv0GSJPU25hr7iUmu6E/V79C3LQZuHjlmVd+2tvbHAD+sqvvXaB8ryfFJlidZvnr16o0oXZKkNs002D8EPBHYF7gVeF/fnjHH1gzax6qq06pqaVUtXbRo0fQqliRpAdh8Jg+qqu9NbSf5CPDZ/u4qYNeRQ3cBbum3x7V/H9g+yeZ9r330eEmSNE0z6rEn2Xnk7hHA1Ij5c4CjkmyVZHdgCfAN4GJgST8Cfku6AXbnVFUBFwIv6R9/LHD2TGqSJEkb0GNP8gngucBjk6wCTgaem2RfutPm3wF+B6CqViQ5C7gauB84oaoe6J/nROA8YDPgjKpa0f+KPwTOTPIO4DLg9In9dZIkLTDrDfaqOnpM81rDt6reCbxzTPu5wLlj2q+nGzUvSZI2kjPPSZLUEINdkqSGGOySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJaojBLklSQwx2SZIaYrBLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSGbD12AJM1X1zx5j6FLmLY9vnXN0CVoltljlySpIQa7JEkNMdglSWrIeoM9yRlJbkty1Ujbo5Ocn+S6/ucOfXuSnJpkZZIrkjxt5DHH9sdfl+TYkfanJ7myf8ypSTLpP1KSpIViQ3rsHwUOXaPtJOCCqloCXNDfB3g+sKS/HQ98CLoPAsDJwDOB/YGTpz4M9MccP/K4NX+XJEnaQOsN9qr6InD7Gs2HAcv67WXA4SPtH6vO14Htk+wMHAKcX1W3V9UdwPnAof2+7arqa1VVwMdGnkuSJE3TTK+x71RVtwL0P3fs2xcDN48ct6pvW1f7qjHtYyU5PsnyJMtXr149w9IlSWrXpAfPjbs+XjNoH6uqTquqpVW1dNGiRTMsUZKkds002L/Xn0an/3lb374K2HXkuF2AW9bTvsuYdkmSNAMzDfZzgKmR7ccCZ4+0H9OPjj8AuLM/VX8ecHCSHfpBcwcD5/X77kpyQD8a/piR55IkSdO03illk3wCeC7w2CSr6Ea3vxs4K8lxwE3Akf3h5wIvAFYC9wCvBKiq25O8Hbi4P+5tVTU1IO81dCPvtwY+198kSdIMrDfYq+rotew6aMyxBZywluc5AzhjTPtyYO/11SFJktbPmeckSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhBrskSQ0x2CVJaojBLklSQwx2SZIaYrBLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSEGuyRJDdmoYE/ynSRXJrk8yfK+7dFJzk9yXf9zh749SU5NsjLJFUmeNvI8x/bHX5fk2I37kyRJWrgm0WN/XlXtW1VL+/snARdU1RLggv4+wPOBJf3teOBD0H0QAE4GngnsD5w89WFAkiRNz2ycij8MWNZvLwMOH2n/WHW+DmyfZGfgEOD8qrq9qu4AzgcOnYW6JElq3sYGewGfT3JJkuP7tp2q6laA/ueOffti4OaRx67q29bWLkmSpmnzjXz8s6vqliQ7Aucn+dY6js2YtlpH+0OfoPvwcDzA4x73uOnWKklS8zaqx15Vt/Q/bwM+Q3eN/Hv9KXb6n7f1h68Cdh15+C7ALetoH/f7TquqpVW1dNGiRRtTuiRJTZpxsCd5ZJJtp7aBg4GrgHOAqZHtxwJn99vnAMf0o+MPAO7sT9WfBxycZId+0NzBfZskSZqmjTkVvxPwmSRTz/M3VfVPSS4GzkpyHHATcGR//LnAC4CVwD3AKwGq6vYkbwcu7o97W1XdvhF1SZK0YM042KvqemCfMe0/AA4a017ACWt5rjOAM2ZaiyRJ6jjznCRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhG7sIjKRN1FOWPWXoEqblymOvHLoEqQn22CVJaojBLklSQwx2SZIaYrBLktQQg12SpIYY7JIkNcRglySpIQa7JEkNMdglSWqIwS5JUkMMdkmSGmKwS5LUEINdkqSGGOySJDXEYJckqSEGuyRJDTHYJUlqiMEuSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkhm0ywJzk0ybVJViY5aeh6JEmajzaJYE+yGfAB4PnAnsDRSfYctipJkuafTSLYgf2BlVV1fVXdB5wJHDZwTZIkzTubSrAvBm4eub+qb5MkSdOw+dAF9DKmrR5yUHI8cHx/9+4k185qVZP1WOD7s/HEec9sPOu8NTuv81vH/RNdsGblNc5v+RqPmLX3C+Lr3Ju11/jEv5yNZwXg8Rty0KYS7KuAXUfu7wLcsuZBVXUacNpcFTVJSZZX1dKh62idr/Ps8zWefb7Gs6/l13hTORV/MbAkye5JtgSOAs4ZuCZJkuadTaLHXlX3JzkROA/YDDijqlYMXJYkSfPOJhHsAFV1LnDu0HXMonl5CWEe8nWefb7Gs8/XePY1+xqn6iFj1CRJ0jy1qVxjlyRJE2CwS5LUEINdkqSGGOxzIMkOibNCzJUkjxy6BmmmkjwmyRFJnj50LZqfDPYJS/InSZ7cb2+V5ELg28D3kvzKsNW1JcniJEv7uQ9IsmOSdwHXDVxaU5I8Pslj++0DkrwhyRFD19WKJJ9Nsne/vTNwFfDbwF8ned2gxTUiyePWdRu6vklzVPyEJVkB7F1V1U+BezTwK8CTgGVVtf+gBTaif8P7I2AlsBXwF8CfAR8D/ntV3Tpgec1I8mbgt+imeD6T7t/yPwPPBL5ZVQbPRkqyoqr26rffBDy5qo5Jsi3wlap66rAVzn9JrqT7Nzx65rSARcCOVbXZIIXNkk3me+wNua8e/LR0CHBmVT0AXJPE13tyjgd+qapu7z9xrwSeU1VfH7iu1hwN7AE8ArgJ+IWquqf/t3z5oJW146cj2wcBHwGoqruS/GyYktpSVU8ZvZ9kN+AP6T6ovmuAkmaVp+In7ydJ9k6yCHge8PmRfY8YqKYW3VtVtwNU1U3Avxrqs+Leqrqvqn4IfLuq7oFutkjgvmFLa8bNSf5rf3njacA/ASTZGthi0Moak2RJko8CnwMuAfasqvcPW9Xk2YOcvNcCn6I7xXNKVd0AkOQFwGVDFtaYXZKcOnJ/x9H7VfV7A9TUou2T/AbdKczt+m36+48arqymHAe8ja73+NL+QxTAAcBfDVZVQ/oxDH8E7AX8d+C4/kxqk7zGPmFJfqOqPj10Ha1Lcuy69lfVsrmqpWVJ1hksVfXKuapFmqkkDwA3A/8IPCTQW+sIGOwTluTSqnra0HUsJEm2Aaqqfjx0LQtJkp2q6ntD1zHfJfkHuoFcU4punfALq+p/D1NVWxZaR8BgnzCDfe4keQ3wRmDqe+t3A++pqg8OV1XbkjwKeDHwMmCPqlo8cEnzXpL/PKb50cArgOuq6qQ5LqlpC6EjYLBPWJJ76EZoP2QX3T8mv7oyAUn+GHgWcGJVXd+3PYHua28XVdU7hqyvJf0grl+nC/OnAdsChwNfrCpHbc+SJJsBl1TVvkPX0oKF1BEw2Ces/x77C9a2v6punMNympXkWmCfqrp3jfat6b5f/aRhKmtLko8Dz6H7dseZwBeAlVW1+6CFLRBJLjfYN95C6wg4Kn7y7jO858aaod63/bvf/Z2ovYE7gGuAb1XVA0nsDUxQkkePad4BOAZYMcfltOo3WaMjUFXXJ/kvwDcBg13r9JWhC1ggViU5qKouGG1MciDgrHMTUlX79FMkvwz4P0luA7ZN8gtV9W8Dl9eKS/j5WdEK+AFwIfCaoYpqzULqCHgqfsL60ZdrfVGr6mNzWE6zkuwFnA18mQffGJ8BPBs4rKrs6cyCJEvpZqM7ElhVVc8auCRpvZJcALxrLR2BN1fV84apbHYY7BOWZNwsRgFeBCyuKs+STEiSh9P1JPeie41XAB8f98lck5XkYcBrq+qUoWtpQZIdgRPo/i0XcDXwgaq6bdDCGrHQOgIG+yzql2p9Od2cxFcD76yqK4atqg1JPl9VBw9dx0KW5Kaqam5lrLmW5NnA3wAfpQud0H374Fjg5VXl5b0JWEgdAYN9FvQLZPwW8HrgIuBPq+raQYtqTJLLqmq/oetYyJLcXFW7Dl3HfJfk68BrquqyNdr3Bf6yqp45TGWarzwtPGFJTqCbL/4C4FBHyM+aR43MW/4QTus7J+wVTMZ2a4Y6QFVd3i/dqo2U5C7G/3udml9kuzkuaVbZY5+wfoTlbcBqfv4fkhPUTFCSH9BdM8uY3VVVvz3HJTVpPW+IWztmZOMluQZ4VlXdsUb7o4GvVtWTh6msHUm2qKqfrv/INvifcvKcuGNu3Gh4z76qssc4+04BPp/kDcClfdvTgff0+7TxLqIbt7AgGOyTt3VVfQsgyVZV9ZOpHUkOADw1PxnjeurSvFNVpyW5BXg7Pz8q/h1V9Q+DFteOBfV+4an4CRtdBGbNBWFcIGZykjwV2HbNEcNJfhm4paq+PUxlkjY1SVYBf7a2/VW11n3z0cOGLqBBWcv2uPuauXcBd41p/3fgz+e4FmnGkpw1sv2eNfZ9fu4ratJmwDZ0CxiNuzXFU/GTt+a6ymvbp42z27g5AapqeZLd5r4cacaWjGz/Kt28F1MWzXEtrbq1qt42dBFzxWCfvF2SnErXO5/apr/v2tWT8/B17Nt6zqqQNt66PvDbGZiMBXW21GCfvD8Y2V6+xr4172vmLk7yqqr6yGhjkuPoZu+S5otHJNmP7tLo1v12+psfUifjhUleB/wicCVwelXdP3BNs8bBc5qXkuwEfAa4jweDfCmwJXCEK49pvkjyz6x74aimFigZQpJPAj8FvgQ8n+7rsq8dtqrZY7BPWJJz1rW/qn59rmpZCJI8j27NcIAVVfWFIeuRtOlJcmVVPaXf3hz4RsvfUPJU/OT9R+Bm4BN0kyIsqGs7A6mRmzSvJHnOuvZX1RfnqpaG/b9Z56rq/m59rnbZY5+wJJvRjWw9Gngq8I/AJ1pbFnBoSRYDnwbu5edXxNqa7lT8dwcsT9pgScZNQlPAPsAuVbXZHJfUnCQPAD+eukv3PnEPzhWv6UqyFV3Avxd4W1WNW6tdM5DkM8DZVfXRNdqPAV5cVYcNUpi0kZL8J+CPgB3olnp29jlNi8E+C/pAfyFdqO8GnAOcYS9ycpJcW1W/NN190qYqyUHAm+l66++qqvMHLqkZ/YI6a1VVt89VLXPBa+wTlmQZ3WCuzwFvraqrBi6pVWNPTyZ52Nr2SZuiJC+k66HfCfzRmtMkayIuofvANHY1SOAJc1vO7LLHPmH9sq1T13LGLdva1LWcoSQ5hW6KyNdV1Y/7tkfSrYZ1b1X93pD1SRuqf89YBXyTMQNA/SaNpsse++RttZDW/R3QfwP+FLgxydSKeY8DlgFvGqwqafr8nvpAkvwS8IaqetXQtUySPfYJcwW3uZVka7rZpAKsrKp7Bi5JmogkuwJHVdV7h65lvutXg/wfwH8A/h54P/BB4JnA+6qqqXXv7bFPXttfkNyEJHkM8DLgyX3TNUk+UVU/GLAsacaSPBY4km7g7WK62RW18T4CfAj4GnAocCnwN8DLq+reIQubDfbYJ2yhrfs7lCR7AF8AzgMuo/tAtR/dHAIHVtW3BixP2mBJtgWOoPuQ+iS6MH9pVe0yaGENSXJ5Ve07cv9muhUiHxiwrFljj33yptb9tec+u94OvLaqzhptTPJi4J3AiwepSpq+24BvAH8MfLmqKskRA9fUmoePLK4DcDfw1PRT0FXVpYNVNgvssU+Y19jnht9jVyuS/D5wFPBIutPDnwTOr6qmvoI1pPUstFNVdeAcljPr7LFPnj31ufHjGe6TNin9wK1TkjyB7tr63wP/IckfAp+pqn8dtMAGVNVzh65hLtljn7AkO1TVHUPX0bp1jGUI3Xfbd53jkqSJSfIUupB/aVU9ceh65rskr6DLu79eo/1VwI+r6m+GqWx2GOwTluQuHjzlM9V7L7qzI1tWlWdJJiDJyevaX1VvnatapNmS5KtV9ayh65jvklwGPKeq7lqjfTvgwqp6+jCVzQ5DZsKqatvR+/2I198Ffge/ujIxGxrcSd5YVX862/VIs8SR8ZOx2ZqhDlBVP0qyxRAFzaaHDV1Aq5Jsn+QtdNNEbgs8o6peP2xVC9KRQxcgaXBb9FNO/5y+47XlAPXMKnvsE9ZPMPF64KXAGcB+VXXnsFUtaA5m1CYtyW+sbRfduuHaeKcDn0rymqr6DkCS3YAP9PuaYrBP3o3AauCvgHuA4/qvSgJOUDMAB5FoU/eidez77JxV0bCq+h9J7gb+Jck2ffPdwLur6kMDljYrDPbJey8Phsm26zpQc8IeuzZpVfXKte3rJ1zSBFTVh4EP98GecdfcW+GoeDUnyTOq6uJ++01V9a6ha5JmIslNVfW4oeuY75K8CLiiqm7s7/8J3eyUN9LNYHnDkPVNmsE+YUlOXdd+1wmfHUn2pJu962jgzqpaOnBJ0kZLcrNzMmy8JFcAB1TVPUl+jW4OjKPp1pc4sqoOGbTACfNU/ORdMnQBC0WSx9P95zwauB94PLB0anCM1AB7XpNRI0s6/wZwelVdAlyS5HcHrGtWGOwTVlXLprb7azlVVU5xOmFJvgo8CjgTeElVXZfkBkNd802SKxkf4AF2muNyWpX+/fge4CC6tdinPHyYkmaPwT4LkrwGeCPdog70ozHfU1UfXOcDNR2r6Sbv2AlYBFyHvRvNT782dAELwJ8DlwM/Aq6pquUA/Ypvtw5Z2GzwGvuEJflj4FnAiVV1fd/2BOAvgIuq6h1D1teSJI+iGwBzNPCLwPbAIVX1jUELk6YhyZOr6lv99lZV9ZORfQdU1deHq64dSRYDOwLfrKqf9W07A1tU1U2DFjdhBvuEJbkW2Keq7l2jfWu6f1BPGqaytiXZkW5SoKOBXR1wpPlidKnnNZd9dhnoyUjyiqr63/32s6vqKyP7Tqyq/zlcdZPnlLKzYM1Q79v+HfjZAOUsCFV1W1W9v18w4z9NtSd5/4BlSRsia9ked18z8/+PbK/5nvDbc1nIXDDYJ29VkoPWbExyIA1ey9kUTX1XtffswQqRNkytZXvcfc3Mgvrw5OC5yfs94OwkX6b76lsBz6ALmMOGLEzSJmmXfv6LjGzT3188XFlNWVAfnrzGPguSPBx4GbAX3X/OFcDHx52i1+zyGqU2dUmOXdf+0a/QamaS3AOspHs/fmK/TX//CVX1kJXf5jN77LPjUODRwOer6ryhi1ngmjvNpuZ8Eti2qlaPNvYDQn80TEnN2WPoAuaS19gnLMkHgd+rStEXAAAHdUlEQVQHHgO8PcmbBy6pSUn2Wce+14zc/Ys5KEfaGKcCvzym/VeBU+a4liZV1Y3jbsAqRgbbtsJT8ROW5Cq6r7s9kOQRwJeq6ulD19WaJNfTzfF8yRrtbwVe5Ol3zRdJrq6qPdeyb0VV7TXXNbUmyXbACXRjFs4BzgdOBN4AXF5VTY1/ssc+efdV1QMA/dzEngqeHUcCf5vkP0I3X2SSD9P1fJ47ZGHSNK3rPcL36Mn4a+CXgCuB/w/4PPAS4LDWQh28xj4bntyvJAT9QI3+fujmjX/qcKW1o6ouSXI48JkkJwCv6ncdWlX3DViaNF23Jdl/zRkTkzyDbupkbbwnVNVTAJL8L+D7wONaXZPdYJ+8BTVIYyhJHk13fexY4O+B/0N3am2bJFTV7UPWJ03DHwBnJfkoD64OuRQ4hm4pYm28n05t9JdJb2g11MFr7LOi70n+InClo+JnR5IbePD7p1OnMosHz4w8YZDCpBnoR8CfAOzdN10FfKCqbhuuqnYkeQD4MQ++V2xNt9Lb1PvFdkPVNhsM9gnrR8XvBXyVbnnAf6iqtw9blaT5IsmWdO8h3zXYNRMG+4Q5Kn5uJHk88MOqurO//zzgcOA7dD0dr7NrXugHfb6/qlb0KxZ+DXiAbi6MN1TVJwYtsAH9pGGvpjuTegVwRlXdP2xVs8cRl5PnqPi5cRYPrne/L/C3wE3AvoDr3ms++eWqWtFvvxL4136g19OB/zZcWU1ZRjdu4UrgBcD7hi1ndjl4bvLWNSr+Z1W11olVNC1bV9Ut/fYr6D6Bvy/Jw4DLB6xLmq7Rs0u/Svchlar6t8R+wYTsOTIq/nTgG+s5fl4z2Cdv3Kj4ALsAb5rjWlo2+o53IPBGgKr6WXw31PzywyS/BnyXbrGo4wCSbE43yEsbb3RU/P2tv0UY7BM2umRof4r4ZcB/AW4A/m6ouhr0hSRn0S2FuwPwBYAkOwMutqP55HfoppX9BeB1VfVvfftBwD8OVlVb9kkyNe9+gK37+46K1/oleRLdd0+PBn5At8DDG6rq8YMW1pi+V/5SYGfgrKr6bt/+HOCvquqJQ9YnSUMx2Ccsyc+ALwHHVdXKvu16v1c9e8acGfl0Vb1/2KqkDZPk/axjTfCq+r05LEcN8FT85L2Yrsd+YZJ/As7EkfETt5YzI6mq5w1amDR9y4cuQG2xxz5LkjyS7nvVR9MN7loGfKaqPj9oYY3wzIgkjWewz4F+XvMjgZdW1YFD19OCJEfQ9difBUydGflfVbX7oIVJ05TknHXtr6pfn6ta1AaDXfOaZ0Y03yVZDdwMfAK4iDUu3VXVvwxRl+Yvg13N8MyI5qMkm9FNTHM08FS6r7h9YmQ2OmlaDHZJ2kQk2You4N8LvM1vd2gmHBUvSQPrA/2FdKG+G92ENZ8esibNX/bYJWlASZbRrcP+OeDMqrpq4JI0zxnskjSg/qubP+7vjr4hNzndqWafwS5JUkNcj12SpIYY7JIkNcRgl+axJL+Q5Mwk305ydZJz+3n0xx27fZLfnaO6Xp3kmBk87jFJLkxyd5L/ORu1Sa3zGrs0T/VL134VWFZVH+7b9gW2raovjTl+N+CzVbX3LNe1eVXdP8PHPhLYj26U+N5VdeJEi5MWAHvs0vz1POCnU6EOUFWXA5cluSDJpUmuTHJYv/vdwBOTXJ7kvQBJ/iDJxUmuSPLWqedJ8uYk30pyfpJPJHlD375vkq/3x38myQ59+z8neVeSfwFem+QtI495YpJ/SnJJki8leXLffmSSq5J8M8kX+/p/XFVfBu6d7RdPapUT1Ejz197AJWPa7wWOqKofJXks8PV+oZGT6HrB+wIkORhYAuxP99Wqc5I8B7iHbvnh/ejeIy4d+T0fA/5rVf1LkrcBJwOv6/dtX1X/uX/ut4zUcxrw6qq6LskzgQ/Szev/J8AhVfXdJNtv/MshCQx2qUUB3tWH9M+AxcBOY447uL9d1t/fhi7otwXOrqp/B0jyD/3PR9GF99SiJMuAvx15vk8+pJBkG7oV+P62u3IAwFb9z68AH01yFs6yJk2MwS7NXyuAl4xpfzmwCHh6Vf00yXeAh485LsCfVtVf/lxj8vszrOfHY9oeBvxw6izBqKp6dd+DfyFweZJ9q+oHM/zdknpeY5fmry8AWyV51VRDkmcAjwdu60P9ef19gLvoeuNTzgN+u+9Vk2Rxkh2BLwMvSvLwft8LAarqTuCOJL/cP/43gXUuKVpVPwJuSHJk/zuSZJ9++4lVdVFV/QnwfWDXGb8Skv4fe+zSPFVVleQI4M+TnER3bf07wFuAU5MsBy4HvtUf/4MkX0lyFfC5qvqDJHsAX+tPk98NvKKqLu6vyX8TuBFYDtzZ/9pjgQ8neQRwPfDKDSj15cCHkvwxsAVwZv/c702yhO7MwQV9G/0Zhu2ALZMcDhxcVVfP8GWSFhy/7ibpIZJsU1V39wH+ReD4qrp06LokrZ89dknjnJZkT7pr88sMdWn+sMcuSVJDHDwnSVJDDHZJkhpisEuS1BCDXZKkhhjskiQ1xGCXJKkh/xcK+WZ4qr26uAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a83d20588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = actual_data.groupby(\"Categories1\").size().plot(kind=\"bar\", figsize=(8, 5))\n",
    "print(actual_data.Categories1.value_counts(),ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=actual_data[['processed_combined_sent',\"Categories1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86554"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split\n",
    "train_x, valid_x, train_y, valid_y = cross_validation.train_test_split(train_data[\"processed_combined_sent\"], train_data['Categories1'],test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=test_data['processed_combined_sent']\n",
    "test_y=test_data[\"Categories1\"]\n",
    "test_2y=test_data[\"Sub_categories1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77898, 8656, 1839)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x),len(valid_x),len(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=100000)\n",
    "tfidf_vect_ngram.fit(train_x)\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random_forest_Chisqure test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 feature selection evaluation calculated for 10000 features 0.998356825592 0.756816081331 0.752039151713\n",
      "chi2 feature selection evaluation calculated for 20000 features 0.998215615292 0.762823475046 0.73844480696\n",
      "chi2 feature selection evaluation calculated for 30000 features 0.998164266092 0.756931608133 0.73898858075\n",
      "chi2 feature selection evaluation calculated for 40000 features 0.998202777992 0.755314232902 0.740619902121\n",
      "chi2 feature selection evaluation calculated for 50000 features 0.998343988292 0.760512939002 0.7362697118\n",
      "chi2 feature selection evaluation calculated for 60000 features 0.998652083494 0.757971349353 0.73681348559\n",
      "chi2 feature selection evaluation calculated for 70000 features 0.998356825592 0.754621072089 0.729744426319\n",
      "chi2 feature selection evaluation calculated for 80000 features 0.998369662893 0.748267097967 0.719412724307\n",
      "chi2 feature selection evaluation calculated for 90000 features 0.998472361293 0.749884473198 0.73735725938\n"
     ]
    }
   ],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "for n in np.arange(10000,100000,10000):\n",
    "    ch1 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "    x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "    x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "    clf =  OneVsRestClassifier(RandomForestClassifier())\n",
    "   \n",
    "    clf.fit(x_train_chi1_kbest, train_y)\n",
    "    \n",
    "    score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "    score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "    score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "    ch2_train.append(score_train)\n",
    "    ch2_valid.append(score_valid)\n",
    "    ch2_test.append(score_test)\n",
    "    \n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "for n in np.arange(10000,100000,10000):\n",
    "    ch1 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "    x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "    x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
    "    #pprint(random_grid)\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    clf = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    #rf_random.fit(train_features, train_labels)\n",
    "    \n",
    "    #clf =  OneVsRestClassifier(RandomForestClassifier())\n",
    "   \n",
    "    clf.fit(x_train_chi1_kbest, train_y)\n",
    "    rf_random.best_params_\n",
    "    score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "    score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "    score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "    ch2_train.append(score_train)\n",
    "    ch2_valid.append(score_valid)\n",
    "    ch2_test.append(score_test)\n",
    "    \n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#ch2_train= []\\n#ch2_valid = []\\n#ch2_test = []\\nch1 = SelectKBest(chi2, k=10000)\\nx_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\\nx_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\\nx_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\\n\\n# Number of trees in random forest\\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\\n# Number of features to consider at every split\\nmax_features = [\\'auto\\', \\'sqrt\\']\\n# Maximum number of levels in tree\\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\\nmax_depth.append(None)\\n# Minimum number of samples required to split a node\\nmin_samples_split = [2, 5, 10]\\n# Minimum number of samples required at each leaf node\\nmin_samples_leaf = [1, 2, 4]\\n# Method of selecting samples for training each tree\\nbootstrap = [True, False]\\n# Create the random grid\\nrandom_grid = {\\'n_estimators\\': n_estimators,\\'max_features\\': max_features,\\'max_depth\\': max_depth,\\n               \\'min_samples_split\\': min_samples_split,\\'min_samples_leaf\\': min_samples_leaf,\\'bootstrap\\': bootstrap}\\nprint(random_grid)\\n    \\n# Use the random grid to search for best hyperparameters\\n# First create the base model to tune\\nrf = RandomForestClassifier()\\n# Random search of parameters, using 3 fold cross validation, \\n# search across 100 different combinations, and use all available cores\\nclf = OneVsRestClassifier(RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1))\\n# Fit the random search model\\n#rf_random.fit(train_features, train_labels)\\n#clf =  OneVsRestClassifier(RandomForestClassifier())\\n   \\nclf.fit(x_train_chi1_kbest, train_y)\\nclf.best_params_\\n\\n#score_train = clf.score(x_train_chi1_kbest, train_y)\\n#score_valid = clf.score(x_validation_chi1_kbest, valid_y)\\n#score_test = clf.score(x_test_chi1_kbest, test_y)\\n    \\n#ch2_train.append(score_train)\\n#ch2_valid.append(score_valid)\\n#ch2_test.append(score_test)\\n    \\n#print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  \\n#print(rf_random.cv_results_)\\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#ch2_train= []\n",
    "#ch2_valid = []\n",
    "#ch2_test = []\n",
    "ch1 = SelectKBest(chi2, k=10000)\n",
    "x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "    \n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "clf = OneVsRestClassifier(RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1))\n",
    "# Fit the random search model\n",
    "#rf_random.fit(train_features, train_labels)\n",
    "#clf =  OneVsRestClassifier(RandomForestClassifier())\n",
    "   \n",
    "clf.fit(x_train_chi1_kbest, train_y)\n",
    "clf.best_params_\n",
    "\n",
    "#score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "#score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "#score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "#ch2_train.append(score_train)\n",
    "#ch2_valid.append(score_valid)\n",
    "#ch2_test.append(score_test)\n",
    "    \n",
    "#print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  \n",
    "#print(rf_random.cv_results_)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "best_random = clf.best_estimator_\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(best_random, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Best Random Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = clf.best_estimator_\n",
    "random_accuracy = evaluate(best_random, x_train_chi1_kbest, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = clf.best_estimator_\n",
    "random_accuracy = evaluate(best_random, x_test_chi1_kbest, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_test_chi1_kbest, test_y)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.LogisticRegression(solver=newton-cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 feature selection evaluation calculated for 10000 features 0.808351947418 0.785235674677 0.754758020663\n",
      "chi2 feature selection evaluation calculated for 20000 features 0.819045418368 0.78696857671 0.764002175095\n",
      "chi2 feature selection evaluation calculated for 30000 features 0.827043056304 0.787892791128 0.772158781947\n",
      "chi2 feature selection evaluation calculated for 40000 features 0.832896865131 0.78800831793 0.768896139206\n",
      "chi2 feature selection evaluation calculated for 50000 features 0.837762201854 0.789163585952 0.769439912996\n",
      "chi2 feature selection evaluation calculated for 60000 features 0.841562042671 0.787777264325 0.769439912996\n",
      "chi2 feature selection evaluation calculated for 70000 features 0.844553133585 0.788585951941 0.768352365416\n",
      "chi2 feature selection evaluation calculated for 80000 features 0.847441526098 0.78800831793 0.767264817836\n",
      "chi2 feature selection evaluation calculated for 90000 features 0.849084700506 0.787892791128 0.767808591626\n"
     ]
    }
   ],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = [] \n",
    "ch2_test = []\n",
    "for n in np.arange(10000,100000,10000):\n",
    "    ch1 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "    x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "    x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "    clf =  linear_model.LogisticRegression(penalty='l2',n_jobs=-1,multi_class='ovr',C=1.0,class_weight=\"balanced\",max_iter=4000,solver='newton-cg')\n",
    "   \n",
    "    clf.fit(x_train_chi1_kbest, train_y)\n",
    "    \n",
    "    score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "    score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "    score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "    ch2_train.append(score_train)\n",
    "    ch2_valid.append(score_valid)\n",
    "    ch2_test.append(score_test)\n",
    "    \n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 feature selection evaluation calculated for 10000 features 0.801535341087 0.778766173752 0.747145187602\n",
      "chi2 feature selection evaluation calculated for 20000 features 0.812613931038 0.78280961183 0.754214246873\n",
      "chi2 feature selection evaluation calculated for 30000 features 0.821060874477 0.782116451017 0.770527460576\n",
      "chi2 feature selection evaluation calculated for 40000 features 0.819674446071 0.778419593346 0.756389342034\n",
      "chi2 feature selection evaluation calculated for 50000 features 0.823782382089 0.77969038817 0.753126699293\n",
      "chi2 feature selection evaluation calculated for 60000 features 0.829584841716 0.77865064695 0.755301794454\n",
      "chi2 feature selection evaluation calculated for 70000 features 0.83478394824 0.781654343808 0.755845568244\n",
      "chi2 feature selection evaluation calculated for 80000 features 0.841587717271 0.784773567468 0.762370853725\n",
      "chi2 feature selection evaluation calculated for 90000 features 0.837672340753 0.779112754159 0.758020663404\n"
     ]
    }
   ],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "for n in np.arange(10000,100000,10000):\n",
    "    ch1 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "    x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "    x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "    clf =  linear_model.LogisticRegression(penalty='l2',n_jobs=-1,multi_class='ovr',C=1.0,class_weight=\"balanced\",max_iter=4000,solver='saga')\n",
    "   \n",
    "    clf.fit(x_train_chi1_kbest, train_y)\n",
    "    \n",
    "    score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "    score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "    score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "    ch2_train.append(score_train)\n",
    "    ch2_valid.append(score_valid)\n",
    "    ch2_test.append(score_test)\n",
    "    \n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 feature selection evaluation calculated for 10000 features 0.811895042235 0.79008780037 0.772702555737\n",
      "chi2 feature selection evaluation calculated for 20000 features 0.821253433978 0.790318853974 0.769983686786\n",
      "chi2 feature selection evaluation calculated for 30000 features 0.826568076202 0.789279112754 0.769983686786\n",
      "chi2 feature selection evaluation calculated for 40000 features 0.831189504223 0.789510166359 0.773246329527\n",
      "chi2 feature selection evaluation calculated for 50000 features 0.83487380934 0.789741219963 0.771615008157\n",
      "chi2 feature selection evaluation calculated for 60000 features 0.837826388354 0.788932532348 0.771615008157\n",
      "chi2 feature selection evaluation calculated for 70000 features 0.840111427765 0.789394639556 0.772158781947\n",
      "chi2 feature selection evaluation calculated for 80000 features 0.842229582274 0.789972273567 0.772158781947\n",
      "chi2 feature selection evaluation calculated for 90000 features 0.843808570182 0.789741219963 0.772702555737\n"
     ]
    }
   ],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "for n in np.arange(10000,100000,10000):\n",
    "    ch1 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "    x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "    x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "    clf =  linear_model.LogisticRegression(n_jobs=-1,multi_class='ovr',C=1.0,max_iter=3000)\n",
    "   \n",
    "    clf.fit(x_train_chi1_kbest, train_y)\n",
    "    \n",
    "    score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "    score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "    score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "    ch2_train.append(score_train)\n",
    "    ch2_valid.append(score_valid)\n",
    "    ch2_test.append(score_test)\n",
    "    \n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 feature selection evaluation calculated for 10000 features 0.837081824951 0.791012014787 0.771071234367\n",
      "chi2 feature selection evaluation calculated for 20000 features 0.859418727053 0.790203327172 0.771615008157\n",
      "chi2 feature selection evaluation calculated for 30000 features 0.872410074713 0.789394639556 0.775421424687\n",
      "chi2 feature selection evaluation calculated for 40000 features 0.881370510154 0.790896487985 0.767808591626\n",
      "chi2 feature selection evaluation calculated for 50000 features 0.887647949883 0.788817005545 0.762370853725\n",
      "chi2 feature selection evaluation calculated for 60000 features 0.892307889805 0.788817005545 0.761827079935\n",
      "chi2 feature selection evaluation calculated for 70000 features 0.895542889419 0.786853049908 0.761827079935\n",
      "chi2 feature selection evaluation calculated for 80000 features 0.897532670929 0.786390942699 0.765089722675\n",
      "chi2 feature selection evaluation calculated for 90000 features 0.898906262035 0.787661737523 0.764545948885\n"
     ]
    }
   ],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "for n in np.arange(10000,100000,10000):\n",
    "    ch1 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "    x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "    x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "    clf = LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False)\n",
    "   \n",
    "    clf.fit(x_train_chi1_kbest, train_y)\n",
    "    \n",
    "    score_train = clf.score(x_train_chi1_kbest, train_y)\n",
    "    score_valid = clf.score(x_validation_chi1_kbest, valid_y)\n",
    "    score_test = clf.score(x_test_chi1_kbest, test_y)\n",
    "    \n",
    "    \n",
    "    ch2_train.append(score_train)\n",
    "    ch2_valid.append(score_valid)\n",
    "    ch2_test.append(score_test)\n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n),score_train,score_valid,score_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_results: [0.84128359545369202, 0.86244096876218534, 0.87493320624467452, 0.88309287581416174, 0.8885663532775876, 0.89227791978972604, 0.89494967000274395, 0.89682711609837817, 0.89808356079314877] \n",
      "valid_results: [0.79244411068106979, 0.78816937207555893, 0.78597423603489114, 0.7863786032002773, 0.78562763560741722, 0.78533880191785566, 0.78447230084917108, 0.78504996822829409, 0.78585870255906654] \n",
      "test_results: [0.77969069156696824, 0.77152028012839213, 0.77239568135395387, 0.77443828421359795, 0.77414648380507733, 0.7758972862562008, 0.77239568135395387, 0.77239568135395387, 0.77122847971987163]\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time print (\"\\ntrain_results:\",ch2_train,\"\\nvalid_results:\",ch2_valid,\"\\ntest_results:\",ch2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-68-5f09196be114>\", line 16, in <module>\n",
      "    clf_rnd.fit(x_train_chi1_kbest, train_y)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 328, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 789, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\", line 638, in get\n",
      "    self.wait(timeout)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\", line 635, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pytest.py\", line 9, in <module>\n",
      "    from _pytest.config import (\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\_pytest\\config.py\", line 14, in <module>\n",
      "    import _pytest._code\n",
      "  File \"C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 8, in <module>\n",
      "    from .source import Source  # noqa\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 764, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 832, in get_data\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "ch1 = SelectKBest(chi2, k=30000)\n",
    "x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "clf_svc = LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False)\n",
    "clf_rnd = OneVsRestClassifier(RandomForestClassifier(bootstrap=False,criterion='gini', n_estimators=2000,max_features='auto',n_jobs=-1,class_weight=\"balanced_subsample\"))\n",
    "clf_nvb = MultinomialNB()\n",
    "clf_log = linear_model.LogisticRegression(n_jobs=-1,multi_class='ovr',C=1.0,class_weight=\"balanced\",max_iter=3000)\n",
    "   \n",
    "clf_svc.fit(x_train_chi1_kbest, train_y)\n",
    "clf_rnd.fit(x_train_chi1_kbest, train_y)\n",
    "clf_nvb.fit(x_train_chi1_kbest, train_y)\n",
    "clf_log.fit(x_train_chi1_kbest, train_y)\n",
    "\n",
    "score_train_clf_svc = clf_svc.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_svc = clf_svc.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_svc = clf_svc.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "score_train_clf_rnd = clf_rnd.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_rnd = clf_rnd.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_rnd = clf_rnd.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "score_train_clf_nvb = clf_nvb.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_nvb = clf_nvb.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_nvb = clf_nvb.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "score_train_clf_log = clf_log.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_log = clf_log.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_log = clf_log.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "test_pred_clf_svc=clf_svc.predict(x_test_chi1_kbest)\n",
    "test_pred_clf_rnd=clf_rnd.predict(x_test_chi1_kbest)\n",
    "test_pred_clf_nvb=clf_nvb.predict(x_test_chi1_kbest)\n",
    "test_pred_clf_log=clf_log.predict(x_test_chi1_kbest)    \n",
    "\n",
    "print(\"LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False) : \\t\",score_train_clf_svc,score_valid_clf_svc,score_test_clf_svc,\n",
    "    \"\\nOneVsRestClassifier(RandomForestClassifier())           : \\t\",score_train_clf_rnd,score_valid_clf_rnd,score_test_clf_rnd,\n",
    "    \"\\nnaive_bayes.MultinomialNB()                             : \\t\",score_train_clf_nvb,score_valid_clf_nvb,score_test_clf_nvb,\n",
    "    \"\\nlinear_model.LogisticRegression                         : \\t\",score_train_clf_log,score_valid_clf_log,score_test_clf_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results based on clean headers + Scapy ents removed 10000 features_TFIDF_chi2,selectbest\n",
    "LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False) : \t 0.839738312898 0.785049968228 0.771520280128 \n",
    "OneVsRestClassifier(RandomForestClassifier())           : \t 0.998498043123 0.758535035527 0.732419025387 \n",
    "naive_bayes.MultinomialNB()                             : \t 0.76377395549 0.744786551903 0.718412605778 \n",
    "linear_model.LogisticRegression                         : \t 0.809049290181 0.782161631333 0.758389261745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results based on removed_scapy ents _ 10000 features_TFIDF_chi2,selectbest\n",
    "LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False) : \t 0.84131247924 0.792444110681 0.779690691567 \n",
    "OneVsRestClassi#fier(RandomForestClassifier())           : \t 0.998108112011 0.762001039801 0.735045229063 \n",
    "naive_bayes.MultinomialNB()                             : \t 0.760105714657 0.742129281959 0.720455208637 \n",
    "linear_model.LogisticRegression                         : \t 0.810738991667 0.78360579978 0.763058068281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <th>PRESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <td>13825</td>\n",
       "      <td>1326</td>\n",
       "      <td>69</td>\n",
       "      <td>304</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <td>1373</td>\n",
       "      <td>21502</td>\n",
       "      <td>335</td>\n",
       "      <td>1291</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>43</td>\n",
       "      <td>166</td>\n",
       "      <td>2215</td>\n",
       "      <td>72</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <td>260</td>\n",
       "      <td>597</td>\n",
       "      <td>68</td>\n",
       "      <td>6577</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRESCRIPTION</th>\n",
       "      <td>93</td>\n",
       "      <td>1499</td>\n",
       "      <td>26</td>\n",
       "      <td>406</td>\n",
       "      <td>14027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               APPOINTMENTS  ASK_A_DOCTOR   LAB  MISCELLANEOUS  PRESCRIPTION\n",
       "APPOINTMENTS          13825          1326    69            304           113\n",
       "ASK_A_DOCTOR           1373         21502   335           1291          2651\n",
       "LAB                      43           166  2215             72            24\n",
       "MISCELLANEOUS           260           597    68           6577           381\n",
       "PRESCRIPTION             93          1499    26            406         14027"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((confusion_matrix(clf_svc.predict(x_train_chi1_kbest),train_y)),[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"],[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <th>PRESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <td>15579</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <td>9</td>\n",
       "      <td>25043</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8627</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRESCRIPTION</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>17180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               APPOINTMENTS  ASK_A_DOCTOR   LAB  MISCELLANEOUS  PRESCRIPTION\n",
       "APPOINTMENTS          15579            12     0              2             1\n",
       "ASK_A_DOCTOR              9         25043     0             10            11\n",
       "LAB                       0             1  2710              0             0\n",
       "MISCELLANEOUS             1             8     2           8627             4\n",
       "PRESCRIPTION              5            26     1             11         17180"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((confusion_matrix(clf_rnd.predict(x_train_chi1_kbest),train_y)),[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"],[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <th>PRESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <td>13735</td>\n",
       "      <td>2538</td>\n",
       "      <td>135</td>\n",
       "      <td>610</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <td>1294</td>\n",
       "      <td>19922</td>\n",
       "      <td>590</td>\n",
       "      <td>1734</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>30</td>\n",
       "      <td>178</td>\n",
       "      <td>1672</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <td>445</td>\n",
       "      <td>916</td>\n",
       "      <td>276</td>\n",
       "      <td>5872</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRESCRIPTION</th>\n",
       "      <td>90</td>\n",
       "      <td>1536</td>\n",
       "      <td>40</td>\n",
       "      <td>361</td>\n",
       "      <td>11431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               APPOINTMENTS  ASK_A_DOCTOR   LAB  MISCELLANEOUS  PRESCRIPTION\n",
       "APPOINTMENTS          13735          2538   135            610           158\n",
       "ASK_A_DOCTOR           1294         19922   590           1734          4573\n",
       "LAB                      30           178  1672             73            18\n",
       "MISCELLANEOUS           445           916   276           5872          1016\n",
       "PRESCRIPTION             90          1536    40            361         11431"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((confusion_matrix(clf_nvb.predict(x_train_chi1_kbest),train_y)),[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"],[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <th>PRESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <td>13646</td>\n",
       "      <td>1746</td>\n",
       "      <td>40</td>\n",
       "      <td>317</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <td>1167</td>\n",
       "      <td>19472</td>\n",
       "      <td>141</td>\n",
       "      <td>849</td>\n",
       "      <td>2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>185</td>\n",
       "      <td>578</td>\n",
       "      <td>2448</td>\n",
       "      <td>223</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <td>481</td>\n",
       "      <td>1338</td>\n",
       "      <td>73</td>\n",
       "      <td>6915</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRESCRIPTION</th>\n",
       "      <td>115</td>\n",
       "      <td>1956</td>\n",
       "      <td>11</td>\n",
       "      <td>346</td>\n",
       "      <td>13657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               APPOINTMENTS  ASK_A_DOCTOR   LAB  MISCELLANEOUS  PRESCRIPTION\n",
       "APPOINTMENTS          13646          1746    40            317           133\n",
       "ASK_A_DOCTOR           1167         19472   141            849          2571\n",
       "LAB                     185           578  2448            223            85\n",
       "MISCELLANEOUS           481          1338    73           6915           750\n",
       "PRESCRIPTION            115          1956    11            346         13657"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((confusion_matrix(clf_log.predict(x_train_chi1_kbest),train_y)),[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"],[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "ch1 = SelectKBest(chi2, k=30000)\n",
    "x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "    \n",
    "    \n",
    "clf_svc = OneVsRestClassifier(LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False))\n",
    "clf_rnd =OneVsRestClassifier(RandomForestClassifier())\n",
    "clf_nvb = OneVsRestClassifier(MultinomialNB())\n",
    "clf_log = OneVsRestClassifier(linear_model.LogisticRegression(n_jobs=-1,multi_class='ovr',C=1.0,class_weight=\"balanced\",max_iter=3000))\n",
    "   \n",
    "clf_svc.fit(x_train_chi1_kbest, train_y)\n",
    "clf_rnd.fit(x_train_chi1_kbest, train_y)\n",
    "clf_nvb.fit(x_train_chi1_kbest, train_y)\n",
    "clf_log.fit(x_train_chi1_kbest, train_y)\n",
    "\n",
    "score_train_clf_svc = clf_svc.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_svc = clf_svc.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_svc = clf_svc.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "score_train_clf_rnd = clf_rnd.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_rnd = clf_rnd.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_rnd = clf_rnd.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "score_train_clf_nvb = clf_nvb.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_nvb = clf_nvb.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_nvb = clf_nvb.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "score_train_clf_log = clf_log.score(x_train_chi1_kbest, train_y)\n",
    "score_valid_clf_log = clf_log.score(x_validation_chi1_kbest, valid_y)\n",
    "score_test_clf_log = clf_log.score(x_test_chi1_kbest, test_y)\n",
    "\n",
    "test_pred_clf_svc=clf_svc.predict(x_test_chi1_kbest)\n",
    "test_pred_clf_rnd=clf_rnd.predict(x_test_chi1_kbest)\n",
    "test_pred_clf_nvb=clf_nvb.predict(x_test_chi1_kbest)\n",
    "test_pred_clf_log=clf_log.predict(x_test_chi1_kbest)    \n",
    "\n",
    "print(\"LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False) : \\t\",score_train_clf_svc,score_valid_clf_svc,score_test_clf_svc,\n",
    "    \"\\nOneVsRestClassifier(RandomForestClassifier())           : \\t\",score_train_clf_rnd,score_valid_clf_rnd,score_test_clf_rnd,\n",
    "    \"\\nnaive_bayes.MultinomialNB()                             : \\t\",score_train_clf_nvb,score_valid_clf_nvb,score_test_clf_nvb,\n",
    "    \"\\nlinear_model.LogisticRegression                         : \\t\",score_train_clf_log,score_valid_clf_log,score_test_clf_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False) : \t 0.841298037347 0.792444110681 0.779398891158 \n",
      "OneVsRestClassifier(RandomForestClassifier())           : \t 0.998382507979 0.758419502051 0.730668222936 \n",
      "naive_bayes.MultinomialNB()                             : \t 0.76628684488 0.745941886662 0.719579807412 \n",
      "linear_model.LogisticRegression                         : \t 0.81042127002 0.780313095719 0.759556463379\n"
     ]
    }
   ],
   "source": [
    "print(\"LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False) : \\t\",score_train_clf_svc,score_valid_clf_svc,score_test_clf_svc,\n",
    "    \"\\nOneVsRestClassifier(RandomForestClassifier())           : \\t\",score_train_clf_rnd,score_valid_clf_rnd,score_test_clf_rnd,\n",
    "    \"\\nnaive_bayes.MultinomialNB()                             : \\t\",score_train_clf_nvb,score_valid_clf_nvb,score_test_clf_nvb,\n",
    "    \"\\nlinear_model.LogisticRegression                         : \\t\",score_train_clf_log,score_valid_clf_log,score_test_clf_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <th>PRESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APPOINTMENTS</th>\n",
       "      <td>13753</td>\n",
       "      <td>1303</td>\n",
       "      <td>62</td>\n",
       "      <td>306</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASK_A_DOCTOR</th>\n",
       "      <td>1433</td>\n",
       "      <td>21626</td>\n",
       "      <td>335</td>\n",
       "      <td>1275</td>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>46</td>\n",
       "      <td>162</td>\n",
       "      <td>2221</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISCELLANEOUS</th>\n",
       "      <td>259</td>\n",
       "      <td>578</td>\n",
       "      <td>74</td>\n",
       "      <td>6612</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRESCRIPTION</th>\n",
       "      <td>103</td>\n",
       "      <td>1421</td>\n",
       "      <td>21</td>\n",
       "      <td>388</td>\n",
       "      <td>14042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               APPOINTMENTS  ASK_A_DOCTOR   LAB  MISCELLANEOUS  PRESCRIPTION\n",
       "APPOINTMENTS          13753          1303    62            306            93\n",
       "ASK_A_DOCTOR           1433         21626   335           1275          2696\n",
       "LAB                      46           162  2221             69            22\n",
       "MISCELLANEOUS           259           578    74           6612           343\n",
       "PRESCRIPTION            103          1421    21            388         14042"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((confusion_matrix(clf_svc.predict(x_train_chi1_kbest),train_y)),[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"],[\"APPOINTMENTS\",\"ASK_A_DOCTOR\",\"LAB\",\"MISCELLANEOUS\",\"PRESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl\n",
    "from pyopencl.tools import get_test_platforms_and_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2_train= []\n",
    "ch2_valid = []\n",
    "ch2_test = []\n",
    "ch1 = SelectKBest(chi2, k=30000)\n",
    "x_train_chi1_kbest = ch1.fit_transform(xtrain_tfidf_ngram,train_y)\n",
    "x_validation_chi1_kbest = ch1.transform(xvalid_tfidf_ngram)\n",
    "x_test_chi1_kbest = ch1.transform(xtest_tfidf_ngram)\n",
    "\n",
    "# classifier\n",
    "clf = LinearSVC(C=1.0,penalty='l1', max_iter=3000,dual=False)\n",
    "y_score = clf.fit(x_train_chi1_kbest, train_y).decision_function(x_test_chi1_kbest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-9cfbe7130291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[1;31m# If key is contained, would have returned by now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 5\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i] = roc_curve(test_y[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.5])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
