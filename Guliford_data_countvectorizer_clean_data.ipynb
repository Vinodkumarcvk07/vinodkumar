{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\1520\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:/VINOD KUMAR/Project_Guf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "actual_data=pd.read_csv(\"Guliford_cleaned_data.csv\")\n",
    "test_data=pd.read_csv(\"Guliford_test_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86554 entries, 0 to 86553\n",
      "Data columns (total 17 columns):\n",
      "FileID                  86554 non-null int64\n",
      "clientid                86554 non-null int64\n",
      "PID                     82817 non-null float64\n",
      "SUMMARY                 83731 non-null object\n",
      "DATA                    86554 non-null object\n",
      "Categories1             86554 non-null object\n",
      "Sub_categories1         86554 non-null object\n",
      "Categories2             1 non-null object\n",
      "Sub_categories2         0 non-null float64\n",
      "Categories3             0 non-null float64\n",
      "Sub_categories3         0 non-null float64\n",
      "Categories4             0 non-null float64\n",
      "Sub_categories4         0 non-null float64\n",
      "Categories5             0 non-null float64\n",
      "Sub_categories5         0 non-null float64\n",
      "Previous_Appointment    86554 non-null object\n",
      "pre_data                86505 non-null object\n",
      "dtypes: float64(8), int64(2), object(7)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "actual_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2279 entries, 0 to 2278\n",
      "Data columns (total 17 columns):\n",
      "FileID                  2279 non-null int64\n",
      "clientid                2279 non-null int64\n",
      "PID                     2279 non-null int64\n",
      "SUMMARY                 2201 non-null object\n",
      "DATA                    2279 non-null object\n",
      "Categories1             2279 non-null object\n",
      "Sub_categories1         2279 non-null object\n",
      "Categories2             0 non-null float64\n",
      "Sub_categories2         0 non-null float64\n",
      "Categories3             0 non-null float64\n",
      "Sub_categories3         0 non-null float64\n",
      "Categories4             0 non-null float64\n",
      "Sub_categories4         0 non-null float64\n",
      "Categories5             0 non-null float64\n",
      "Sub_categories5         0 non-null float64\n",
      "Previous_Appointment    2279 non-null object\n",
      "pre_data                2278 non-null object\n",
      "dtypes: float64(8), int64(3), object(6)\n",
      "memory usage: 302.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data=actual_data[[\"SUMMARY\",\"pre_data\",\"Categories1\",\"Sub_categories1\"]]\n",
    "test_data=test_data[[\"SUMMARY\",\"pre_data\",\"Categories1\",\"Sub_categories1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data.columns=[\"summary\",\"data\",\"categories\",\"sub_categories\"]\n",
    "test_data.columns=[\"summary\",\"data\",\"categories\",\"sub_categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting datatype of summary feature\n",
    "actual_data.summary =actual_data.summary.astype('str')\n",
    "actual_data.data =actual_data.data.astype('str')\n",
    "actual_data.categories=actual_data.categories.astype(\"category\")\n",
    "actual_data.sub_categories=actual_data.sub_categories.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.summary =test_data.summary.astype('str')\n",
    "test_data.data =test_data.data.astype('str')\n",
    "test_data.categories=test_data.categories.astype(\"category\")\n",
    "test_data.sub_categories=test_data.sub_categories.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some Preprocessing\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def raw_to_prepwithtokenize( raw_review ):\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    low_case = letters_only.lower()\n",
    "    words = nltk.word_tokenize(low_case)\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    processed_sentence = \" \".join(meaningful_words)\n",
    "    return(processed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86554"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_data=len(actual_data)\n",
    "length_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 10000\n",
      "no.of rows reviews processed: 20000\n",
      "no.of rows reviews processed: 30000\n",
      "no.of rows reviews processed: 40000\n",
      "no.of rows reviews processed: 50000\n",
      "no.of rows reviews processed: 60000\n",
      "no.of rows reviews processed: 70000\n",
      "no.of rows reviews processed: 80000\n"
     ]
    }
   ],
   "source": [
    "process=[]\n",
    "summary_process=[]\n",
    "for i in range (0,length_data):\n",
    "    if i%10000 == 0:\n",
    "        print (\"no.of rows reviews processed:\",i)\n",
    "    process.append(raw_to_prepwithtokenize(actual_data['data'][i]))\n",
    "    summary_process.append(raw_to_prepwithtokenize(actual_data['summary'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_test_data=len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\1520\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows reviews processed: 1000\n",
      "no.of rows reviews processed: 2000\n"
     ]
    }
   ],
   "source": [
    "process_test=[]\n",
    "summary_test=[]\n",
    "for i in range (0,length_test_data):\n",
    "    if i%1000 == 0:\n",
    "        print (\"no.of rows reviews processed:\",i)\n",
    "    process_test.append(raw_to_prepwithtokenize(test_data['data'][i]))\n",
    "    summary_test.append(raw_to_prepwithtokenize(test_data['summary'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data[\"data\"]=pd.DataFrame(process)\n",
    "actual_data[\"summary\"]=pd.DataFrame(summary_process)\n",
    "test_data[\"data\"]=pd.DataFrame(process_test)\n",
    "test_data[\"summary\"]=pd.DataFrame(summary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data=pd.concat([actual_data[\"summary\"],actual_data[\"data\"]],axis=1)\n",
    "target=actual_data.categories\n",
    "pre_test_data = pd.concat([test_data[\"summary\"],test_data[\"data\"]],axis=1)\n",
    "test_target=test_data.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_val, Y_train, Y_test_val = train_test_split(pre_data,target, test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pre_data\n",
    "del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object): #tokenizer for CountVectorizer for stemming using Wordnet Corpora\n",
    "      def __init__(self):\n",
    "            self.wnl = WordNetLemmatizer()  \n",
    "      def __call__(self, doc):  \n",
    "            return [self.wnl.lemmatize(t) for t in word_tokenize(doc)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vectorizer= CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english',strip_accents='unicode',\n",
    "#                         max_df=0.8,min_df=5,lowercase = True,ngram_range=(1,1),max_features=1000)\n",
    "count_vectorizer= CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english',strip_accents='unicode',\n",
    "                                  max_df=0.5,lowercase = True,ngram_range=(1,1),max_features=1000)\n",
    "count_actual_data=count_vectorizer.fit_transform(X_train[\"data\"])\n",
    "count_val_data=count_vectorizer.fit_transform(X_test_val[\"data\"])\n",
    "count_test_data=count_vectorizer.fit_transform(pre_test_data[\"data\"])\n",
    "\n",
    "count_actual_summary=count_vectorizer.fit_transform(X_train[\"summary\"])\n",
    "count_val_summary=count_vectorizer.fit_transform(X_test_val[\"summary\"])\n",
    "count_test_summary=count_vectorizer.fit_transform(pre_test_data[\"summary\"])\n",
    "\n",
    "dense_actual_data=count_actual_data.todense()\n",
    "dense_val_data=count_val_data.todense()\n",
    "dense_test_data=count_test_data.todense()\n",
    "\n",
    "dense_actual_summay=count_actual_summary.todense()\n",
    "dense_val_summay=count_val_summary.todense()\n",
    "dense_test_summary=count_test_summary.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dense_actual_summay=pd.DataFrame(dense_actual_summay, columns=count_vectorizer.get_feature_names())\n",
    "df_dense_val_summay=pd.DataFrame(dense_val_summay, columns=count_vectorizer.get_feature_names())\n",
    "df_dense_test_summary=pd.DataFrame(dense_test_summary, columns=count_vectorizer.get_feature_names())\n",
    "df_dense_actual_data=pd.DataFrame(dense_actual_data, columns=count_vectorizer.get_feature_names())\n",
    "df_dense_val_data=pd.DataFrame(dense_val_data, columns=count_vectorizer.get_feature_names())\n",
    "df_dense_test_data=pd.DataFrame(dense_test_data, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data=pd.concat([df_dense_actual_summay,df_dense_actual_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_data=pd.concat([df_dense_val_summay,df_dense_val_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data=pd.concat([df_dense_test_summary,df_dense_test_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_data, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train= nb.predict(X_train_data)\n",
    "y_pred_val=nb.predict(X_val_data)\n",
    "y_pred_test=nb.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680357581271753\n",
      "0.4488475535786494\n",
      "0.43264589732338743\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(Y_train, y_pred_train))\n",
    "print(metrics.accuracy_score(Y_test_val, y_pred_val))\n",
    "print(metrics.accuracy_score(test_target, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 24 277   6  17  92]\n",
      " [ 29 819   9  31  85]\n",
      " [  2  59   2   2  13]\n",
      " [ 12 215   5   9  66]\n",
      " [  7 337  13  16 132]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(test_target, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " APPOINTMENTS       0.32      0.06      0.10       416\n",
      " ASK_A_DOCTOR       0.48      0.84      0.61       973\n",
      "          LAB       0.06      0.03      0.04        78\n",
      "MISCELLANEOUS       0.12      0.03      0.05       307\n",
      " PRESCRIPTION       0.34      0.26      0.30       505\n",
      "\n",
      "  avg / total       0.36      0.43      0.35      2279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_target, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_data, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_pred_train= logreg.predict(X_train_data)\n",
    "y_log_pred_val=logreg.predict(X_val_data)\n",
    "y_log_pred_test=logreg.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249209306355877\n",
      "0.4490208537923863\n",
      "0.43878894251864853\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_train, y_log_pred_train))\n",
    "print(metrics.accuracy_score(Y_test_val, y_log_pred_val))\n",
    "print(metrics.accuracy_score(test_target, y_log_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_random = RandomForestClassifier(n_estimators = 500)\n",
    "model_fit = model_random.fit(X_train_data,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_pred_train= model_random.predict(X_train_data)\n",
    "y_rf_pred_val=model_random.predict(X_val_data)\n",
    "y_rf_pred_test=model_random.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996389526739164\n",
      "0.4716654150540119\n",
      "0.37735849056603776\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_train, y_rf_pred_train))\n",
    "print(metrics.accuracy_score(Y_test_val, y_rf_pred_val))\n",
    "print(metrics.accuracy_score(test_target, y_rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
